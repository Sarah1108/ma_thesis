{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54d72ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719e1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file= 'data/dataset.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e7dd299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary to map parties to num for tensors\n",
    "party_dict={'SPÖ':0,'ÖVP':1,'FPÖ':2,'Grüne':3,'LIF':4,'BZÖ':5,'NEOS':6,'STRONACH':7,'PILZ':8,'independent':9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c95e8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "takes data set and filters out independet speeches to a seperate list,\n",
    "takes other speeches as list and\n",
    "according party-labels are mapped to number as a list\n",
    "'''\n",
    "def load_data(data_file):\n",
    "    df = pd.read_pickle(data_file)\n",
    "    independent_df= df[df['party']=='independent']\n",
    "    df = df[~(df['party']=='independent')]\n",
    "    df= df[2000:3000]\n",
    "    #print(df['party'])\n",
    "    texts = df['text'].tolist()\n",
    "    df['party'] = df['party'].map(party_dict)\n",
    "    labels = df['party'].tolist()\n",
    "    test_texts= independent_df['text'].tolist()\n",
    "    print(df.value_counts('party'))\n",
    "    #print(labels)\n",
    "    return texts, labels, test_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f8c548f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "party\n",
      "1    329\n",
      "0    281\n",
      "2    194\n",
      "3    188\n",
      "4      8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "texts,labels,test_texts = load_data(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0b2d65",
   "metadata": {},
   "source": [
    "##### Distribution of labels with all speeches\n",
    "[24747/87883,24063/87883,17308/87883,12455/87883,1942/87883,4170/87883,1866/87883,1322/87883,346/87883]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfee493",
   "metadata": {},
   "source": [
    "Distribution for sample 2000:3000\n",
    "1    348/1000\n",
    "0    268/1000\n",
    "2    195/1000\n",
    "3    186/1000\n",
    "4      3/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf3d2eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "takes a list of texts and a list of labels and returns a tensor with tokenzied text and labels\n",
    "truncated with given maximal length and using predefined tokenizer\n",
    "'''\n",
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label,dtype=torch.long)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08ee8058",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "BERT Classifier with a BERT layer, Dropout layer and a linear layer\n",
    "'''\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name, num_classes):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        x = self.dropout(pooled_output)\n",
    "        logits = self.fc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8579ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "training function loads in batches\n",
    "crossentropyloss with weights according to distribution of labels in training data\n",
    "'''\n",
    "def train(model, data_loader, optimizer, scheduler, device, weights):\n",
    "    model.train()\n",
    "    cross_entropy_loss=0\n",
    "    for batch in data_loader:\n",
    "        #Reset gradients before first run - if training\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        #forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        #cross_entropy_loss.append(loss)\n",
    "        #backpropagation with optimizer step\n",
    "        loss.backward()\n",
    "        cross_entropy_loss+=loss.item()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    cross_entropy_loss= cross_entropy_loss/len(data_loader)\n",
    "    return cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f7e6ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            #softmax activation function whyyyyy 1 and 0\n",
    "            probs = nn.functional.softmax(outputs, dim=1)\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "            actual_labels.extend(labels.cpu().tolist())\n",
    "            all_probs.extend(probs.cpu().tolist())\n",
    "    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions), all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4d3cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_party(text, model, tokenizer, device, max_length=128):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        \n",
    "    return preds.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eeb2798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "#bert_model_name = 'bert-base-uncased'\n",
    "bert_model_name= 'bert-base-german-cased'\n",
    "#n-classes depends on sample size, actually 10\n",
    "num_classes = 5\n",
    "max_length = 128\n",
    "batch_size = 10\n",
    "num_epochs = 5\n",
    "learning_rate = 2e-5\n",
    "#because the data set is not balanced n sample to implement weights in loss function\n",
    "class_weights= torch.tensor([31/100,23/100,25/100,21/100])\n",
    "# [1/nsamplesperclass]\n",
    "#class_weights = torch.tensor([24747/87883,24063/87883,17308/87883,12455/87883,1942/87883,4170/87883,1866/87883,1322/87883,346/87883])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d7cdd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3828ab84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "tokenizer.truncation_side= \"left\"\n",
    "train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n",
    "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8c78281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch keys: dict_keys(['input_ids', 'attention_mask', 'label'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch keys:\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch features shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Should be [batch_size, input_dim]\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch labels shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)      \u001b[38;5;66;03m# Should be [batch_size]\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'features'"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(\"Batch keys:\", batch.keys())\n",
    "    print(\"Batch features shape:\", batch['features'].shape)  # Should be [batch_size, input_dim]\n",
    "    print(\"Batch labels shape:\", batch['label'].shape)      # Should be [batch_size]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ddb5fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERTClassifier(bert_model_name, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80b7437d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#not sure if SGD would be better?\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "#optimizer =\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12b29efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_graph=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e98bc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3400\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.06      0.11        64\n",
      "           1       0.33      0.98      0.50        63\n",
      "           2       0.00      0.00      0.00        41\n",
      "           3       0.40      0.07      0.12        28\n",
      "           4       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.34       200\n",
      "   macro avg       0.25      0.22      0.15       200\n",
      "weighted avg       0.32      0.34      0.21       200\n",
      "\n",
      "[[0.1501069962978363, 0.5415072441101074, 0.2423843890428543, 0.052603304386138916, 0.013398073613643646], [0.20838767290115356, 0.5528419613838196, 0.15755513310432434, 0.06960504502058029, 0.011610232293605804], [0.32425329089164734, 0.29030802845954895, 0.1786903291940689, 0.19566784799098969, 0.011080377735197544], [0.26021498441696167, 0.44964975118637085, 0.19252261519432068, 0.0856640636920929, 0.011948463506996632], [0.19399403035640717, 0.5202205181121826, 0.20315028727054596, 0.07141340523958206, 0.011221828870475292], [0.26628929376602173, 0.34872475266456604, 0.22203277051448822, 0.15170609951019287, 0.011247077956795692], [0.2314445823431015, 0.4796927571296692, 0.20989277958869934, 0.06726428121328354, 0.011705507524311543], [0.22908347845077515, 0.43255066871643066, 0.196177676320076, 0.12895692884922028, 0.013231271877884865], [0.18220075964927673, 0.5318706035614014, 0.2197648584842682, 0.05603277310729027, 0.01013097632676363], [0.278344064950943, 0.41480132937431335, 0.18933473527431488, 0.10537275671958923, 0.012147041969001293], [0.2594696879386902, 0.4533090889453888, 0.21439380943775177, 0.06296923011541367, 0.009858286008238792], [0.283888578414917, 0.36640164256095886, 0.17562328279018402, 0.16130611300468445, 0.012780421413481236], [0.3124999403953552, 0.2559015154838562, 0.21267752349376678, 0.20867983996868134, 0.01024110522121191], [0.2477232962846756, 0.46244749426841736, 0.1849251538515091, 0.09584250301122665, 0.009061537683010101], [0.2611846625804901, 0.38068127632141113, 0.2234603613615036, 0.1251513659954071, 0.00952224526554346], [0.3339105248451233, 0.19933857023715973, 0.18943069875240326, 0.2641846537590027, 0.013135458342730999], [0.24585236608982086, 0.41295912861824036, 0.17394424974918365, 0.15183107554912567, 0.01541330385953188], [0.2798791229724884, 0.33141854405403137, 0.19503848254680634, 0.18326248228549957, 0.010401495732367039], [0.1801776885986328, 0.5023833513259888, 0.24724674224853516, 0.06061286851763725, 0.009579356759786606], [0.35188719630241394, 0.2361241728067398, 0.18626238405704498, 0.21444924175739288, 0.011277003213763237], [0.22283819317817688, 0.5020010471343994, 0.1676882952451706, 0.09820140898227692, 0.009271016344428062], [0.20034226775169373, 0.545127272605896, 0.1785367727279663, 0.06522368639707565, 0.010769965127110481], [0.2744583785533905, 0.4030854403972626, 0.17586879432201385, 0.13683763146400452, 0.009749640710651875], [0.19995534420013428, 0.5533385276794434, 0.17805452644824982, 0.055175211280584335, 0.01347629725933075], [0.28318890929222107, 0.3133043348789215, 0.1857016235589981, 0.20198440551757812, 0.0158206969499588], [0.1643594652414322, 0.6047530174255371, 0.168767049908638, 0.049117330461740494, 0.013003038242459297], [0.22639714181423187, 0.49821603298187256, 0.1989596039056778, 0.06269902735948563, 0.013728191144764423], [0.2132800668478012, 0.5094477534294128, 0.20392829179763794, 0.06390052288770676, 0.009443439543247223], [0.2818300127983093, 0.337615430355072, 0.20667211711406708, 0.16180938482284546, 0.01207292452454567], [0.3203392028808594, 0.27004274725914, 0.17406347393989563, 0.2204025387763977, 0.015152058564126492], [0.28944364190101624, 0.3635152280330658, 0.21796651184558868, 0.11838100105524063, 0.010693659074604511], [0.26243337988853455, 0.404117226600647, 0.22237850725650787, 0.10258159786462784, 0.008489305153489113], [0.20105385780334473, 0.5223438143730164, 0.20071345567703247, 0.06105289235711098, 0.014836030080914497], [0.20253312587738037, 0.46867626905441284, 0.2536676228046417, 0.06354962289333344, 0.011573394760489464], [0.17481683194637299, 0.5515546798706055, 0.20478065311908722, 0.05596306920051575, 0.012884710915386677], [0.2945619225502014, 0.30030250549316406, 0.2130814790725708, 0.1804807484149933, 0.01157332118600607], [0.16333062946796417, 0.5907825827598572, 0.18075542151927948, 0.05186998099088669, 0.013261443935334682], [0.24895824491977692, 0.4851318597793579, 0.1584477573633194, 0.09643284231424332, 0.0110293198376894], [0.26511120796203613, 0.42315828800201416, 0.1633264720439911, 0.1369473785161972, 0.011456617154181004], [0.137753427028656, 0.6121484041213989, 0.18490231037139893, 0.05244271084666252, 0.012753200717270374], [0.29547402262687683, 0.4367271065711975, 0.14183558523654938, 0.11574248969554901, 0.010220750235021114], [0.2274378091096878, 0.45539578795433044, 0.22117559611797333, 0.08342456072568893, 0.01256619580090046], [0.22733758389949799, 0.48082253336906433, 0.20900291204452515, 0.07385465502738953, 0.008982316590845585], [0.2174643576145172, 0.449002742767334, 0.23891782760620117, 0.08370472490787506, 0.010910365730524063], [0.16502559185028076, 0.593707799911499, 0.1607999950647354, 0.06328456103801727, 0.017182059586048126], [0.2204914689064026, 0.48098310828208923, 0.18808789551258087, 0.0988556295633316, 0.011581916362047195], [0.15386894345283508, 0.5932456851005554, 0.19558721780776978, 0.045543938875198364, 0.011754193343222141], [0.1761152595281601, 0.5706757307052612, 0.17864678800106049, 0.057317811995744705, 0.017244389280676842], [0.17123796045780182, 0.5724426507949829, 0.18269726634025574, 0.06193603202700615, 0.011686109006404877], [0.23177817463874817, 0.4169641435146332, 0.24369390308856964, 0.09824385493993759, 0.009319940581917763], [0.20948413014411926, 0.573371171951294, 0.1531739979982376, 0.04994228482246399, 0.014028316363692284], [0.16853764653205872, 0.5653113126754761, 0.20998987555503845, 0.04555772244930267, 0.010603494010865688], [0.14108054339885712, 0.6397566199302673, 0.14716213941574097, 0.05431501194834709, 0.017685720697045326], [0.17604106664657593, 0.5392159819602966, 0.2038092166185379, 0.06843455135822296, 0.012499230913817883], [0.2613150477409363, 0.28972116112709045, 0.25195667147636414, 0.18532410264015198, 0.01168295182287693], [0.15864625573158264, 0.5676440596580505, 0.21012774109840393, 0.050028786063194275, 0.01355323288589716], [0.26620030403137207, 0.392046719789505, 0.21035853028297424, 0.12084629386663437, 0.010548039339482784], [0.2994372248649597, 0.3166557252407074, 0.21494999527931213, 0.15916559100151062, 0.009791458025574684], [0.12069062143564224, 0.6616483926773071, 0.1350381225347519, 0.06538597494363785, 0.017236903309822083], [0.21694228053092957, 0.5037204027175903, 0.1837211549282074, 0.08242309093475342, 0.013193092308938503], [0.20448267459869385, 0.478464812040329, 0.17925213277339935, 0.12368638068437576, 0.014113937504589558], [0.2577535808086395, 0.46798840165138245, 0.17296148836612701, 0.09081453830003738, 0.010482043027877808], [0.27851489186286926, 0.22092291712760925, 0.20833268761634827, 0.279823362827301, 0.012406128458678722], [0.20222367346286774, 0.5475248098373413, 0.1752423793077469, 0.06287288665771484, 0.01213625818490982], [0.27211517095565796, 0.3686211109161377, 0.20674869418144226, 0.14252035319805145, 0.009994697757065296], [0.21910959482192993, 0.5113368630409241, 0.19430749118328094, 0.064640574157238, 0.010605408810079098], [0.24811765551567078, 0.4323854148387909, 0.21647761762142181, 0.09070909768342972, 0.012310185469686985], [0.23774464428424835, 0.3657664954662323, 0.21043984591960907, 0.17118406295776367, 0.014864934608340263], [0.2225346714258194, 0.4894784390926361, 0.20010915398597717, 0.07582030445337296, 0.01205743383616209], [0.20850257575511932, 0.47298210859298706, 0.21625353395938873, 0.09255453199148178, 0.009707272052764893], [0.23851464688777924, 0.5163694620132446, 0.16846227645874023, 0.06588113307952881, 0.010772480629384518], [0.25528669357299805, 0.47389212250709534, 0.16974641382694244, 0.08783930540084839, 0.013235503807663918], [0.2667757570743561, 0.3923848569393158, 0.21269328892230988, 0.1160895898938179, 0.012056512758135796], [0.22380316257476807, 0.5048453211784363, 0.1840139776468277, 0.07459689676761627, 0.012740659527480602], [0.2381078451871872, 0.43010711669921875, 0.21374982595443726, 0.10709834843873978, 0.010936839506030083], [0.1500701755285263, 0.6037733554840088, 0.1786004602909088, 0.05378733202815056, 0.013768688775599003], [0.32348912954330444, 0.3478367030620575, 0.18143054842948914, 0.1352115124464035, 0.012032123282551765], [0.1866137981414795, 0.5542519092559814, 0.19196109473705292, 0.05369533598423004, 0.013477816246449947], [0.24383702874183655, 0.40203607082366943, 0.22978954017162323, 0.11073017120361328, 0.013607210479676723], [0.15773232281208038, 0.5937168002128601, 0.17420777678489685, 0.05915766954421997, 0.015185413882136345], [0.2709231674671173, 0.3156188726425171, 0.24529065191745758, 0.1557198315858841, 0.012447488494217396], [0.2608555257320404, 0.22087639570236206, 0.19917406141757965, 0.30537745356559753, 0.013716629706323147], [0.16673140227794647, 0.586632251739502, 0.17608052492141724, 0.056374456733465195, 0.014181382022798061], [0.21395878493785858, 0.4945352077484131, 0.2087922990322113, 0.07322392612695694, 0.009489847347140312], [0.29630354046821594, 0.4044376611709595, 0.16346612572669983, 0.1260056048631668, 0.0097871208563447], [0.18192468583583832, 0.5743340849876404, 0.16176512837409973, 0.06988995522260666, 0.012086087837815285], [0.3232658803462982, 0.32925254106521606, 0.18130846321582794, 0.1547297239303589, 0.01144339144229889], [0.2705688178539276, 0.4210672676563263, 0.2063424289226532, 0.09205808490514755, 0.009963389486074448], [0.2314932644367218, 0.45621928572654724, 0.17878246307373047, 0.11738448590040207, 0.01612042263150215], [0.2733171880245209, 0.4640987515449524, 0.1770041435956955, 0.07477257400751114, 0.010807271115481853], [0.2471763789653778, 0.36039355397224426, 0.24524976313114166, 0.13656820356845856, 0.010612079873681068], [0.31405210494995117, 0.4049932062625885, 0.15228520333766937, 0.11818177998065948, 0.010487722232937813], [0.2879200875759125, 0.32325029373168945, 0.2059623748064041, 0.16707083582878113, 0.01579643040895462], [0.2190396636724472, 0.5043123364448547, 0.15947188436985016, 0.10622712969779968, 0.010949067771434784], [0.32812929153442383, 0.3162064254283905, 0.15504077076911926, 0.1890774816274643, 0.011546144261956215], [0.21356439590454102, 0.534308671951294, 0.18616947531700134, 0.05022473260760307, 0.015732618048787117], [0.2466304749250412, 0.39685341715812683, 0.19044238328933716, 0.15582509338855743, 0.010248513892292976], [0.2483794093132019, 0.4571102261543274, 0.21116945147514343, 0.07169570028781891, 0.011645237915217876], [0.2291240245103836, 0.5001770853996277, 0.1993148922920227, 0.06095568835735321, 0.010428311303257942], [0.3070182502269745, 0.18434251844882965, 0.18271809816360474, 0.31251659989356995, 0.013404607772827148], [0.1875760704278946, 0.5653460621833801, 0.1722852885723114, 0.05671735107898712, 0.018075237050652504], [0.18705658614635468, 0.5709260702133179, 0.17912355065345764, 0.04981778934597969, 0.013075951486825943], [0.31357482075691223, 0.33577001094818115, 0.17161747813224792, 0.16891810297966003, 0.010119505226612091], [0.16258078813552856, 0.5921599864959717, 0.1408248394727707, 0.08921552449464798, 0.015218912623822689], [0.1832651048898697, 0.5213910937309265, 0.2015637755393982, 0.07650798559188843, 0.017271999269723892], [0.2445337474346161, 0.47982171177864075, 0.1913200318813324, 0.07450710982084274, 0.009817413054406643], [0.18255357444286346, 0.5287702083587646, 0.2191813737154007, 0.056259818375110626, 0.01323502603918314], [0.24193139374256134, 0.476532518863678, 0.22027072310447693, 0.051431093364953995, 0.009834183380007744], [0.16620981693267822, 0.5531042218208313, 0.20577582716941833, 0.06153704226016998, 0.013373112305998802], [0.2612791359424591, 0.39181819558143616, 0.22431904077529907, 0.11118829250335693, 0.011395378969609737], [0.17545968294143677, 0.4854806661605835, 0.2594693601131439, 0.06590494513511658, 0.013685307465493679], [0.25346845388412476, 0.23746611177921295, 0.20401374995708466, 0.28860026597976685, 0.016451429575681686], [0.29029354453086853, 0.3290967047214508, 0.22294554114341736, 0.14635689556598663, 0.011307301931083202], [0.2060679793357849, 0.5303667783737183, 0.18336190283298492, 0.06752461194992065, 0.012678747996687889], [0.2632754147052765, 0.27615630626678467, 0.17582330107688904, 0.269976943731308, 0.014768040738999844], [0.19930317997932434, 0.4891342222690582, 0.24676842987537384, 0.055155955255031586, 0.00963814090937376], [0.2904356122016907, 0.2720526158809662, 0.1728888601064682, 0.2508300840854645, 0.013792897574603558], [0.2464299201965332, 0.39687660336494446, 0.22992224991321564, 0.11250581592321396, 0.014265399426221848], [0.18786372244358063, 0.5424180030822754, 0.19022555649280548, 0.06985798478126526, 0.009634786285459995], [0.2726241648197174, 0.36676129698753357, 0.18128006160259247, 0.16944102942943573, 0.009893334470689297], [0.27718472480773926, 0.27260303497314453, 0.19466112554073334, 0.23116998374462128, 0.02438109740614891], [0.1932353973388672, 0.5269876718521118, 0.22280490398406982, 0.044832732528448105, 0.01213926449418068], [0.20410248637199402, 0.5579357743263245, 0.1667531132698059, 0.056397296488285065, 0.014811263419687748], [0.25211209058761597, 0.3999786674976349, 0.1905946433544159, 0.14230182766914368, 0.015012781135737896], [0.17717929184436798, 0.5690252780914307, 0.1949656754732132, 0.045162368565797806, 0.013667355291545391], [0.22017480432987213, 0.4318501055240631, 0.21529768407344818, 0.1231459528207779, 0.009531457908451557], [0.18085549771785736, 0.5685051679611206, 0.1781463623046875, 0.05869588255882263, 0.013797075487673283], [0.2940670847892761, 0.3821347951889038, 0.18273980915546417, 0.1286780685186386, 0.012380169704556465], [0.1735444813966751, 0.5135180354118347, 0.25199463963508606, 0.0481354184448719, 0.01280737854540348], [0.22263003885746002, 0.4842999577522278, 0.20579853653907776, 0.07382719218730927, 0.013444324024021626], [0.24818293750286102, 0.37897345423698425, 0.2719590961933136, 0.08947844058275223, 0.011406064964830875], [0.2625051736831665, 0.19352580606937408, 0.22507111728191376, 0.3000003397464752, 0.01889749802649021], [0.1496874988079071, 0.6072108149528503, 0.16973285377025604, 0.05854323133826256, 0.01482557225972414], [0.3010143041610718, 0.3365636467933655, 0.1803554892539978, 0.17123635113239288, 0.010830155573785305], [0.2725456655025482, 0.32402503490448, 0.23360934853553772, 0.15841814875602722, 0.01140180416405201], [0.25400587916374207, 0.4163427948951721, 0.20043420791625977, 0.11838997155427933, 0.010827088728547096], [0.20860116183757782, 0.5518098473548889, 0.15271911025047302, 0.07688818126916885, 0.009981641545891762], [0.1306595355272293, 0.6376184225082397, 0.1570342779159546, 0.054716069251298904, 0.019971732050180435], [0.19428376853466034, 0.48173463344573975, 0.2298932522535324, 0.08508629351854324, 0.009002008475363255], [0.25527361035346985, 0.4552302062511444, 0.19761091470718384, 0.08028337359428406, 0.01160183921456337], [0.2366001456975937, 0.4156125783920288, 0.22773444652557373, 0.10884840786457062, 0.011204354465007782], [0.12055139243602753, 0.6057767868041992, 0.17539918422698975, 0.07852420955896378, 0.01974843442440033], [0.1646709442138672, 0.578851580619812, 0.19218160212039948, 0.051379550248384476, 0.012916315346956253], [0.1585647612810135, 0.6100099682807922, 0.1491183638572693, 0.06846297532320023, 0.013843921013176441], [0.2621755599975586, 0.45361992716789246, 0.16924862563610077, 0.10634579509496689, 0.00861008558422327], [0.26824769377708435, 0.4287932813167572, 0.1641710102558136, 0.12863847613334656, 0.010149477049708366], [0.29415586590766907, 0.3764757215976715, 0.1810111403465271, 0.13780272006988525, 0.010554585605859756], [0.1985502392053604, 0.5267682075500488, 0.17864342033863068, 0.08451405167579651, 0.011524079367518425], [0.1642696112394333, 0.5714004039764404, 0.20566584169864655, 0.04362621158361435, 0.015037932433187962], [0.28803056478500366, 0.3637743294239044, 0.15263201296329498, 0.1805887073278427, 0.014974416233599186], [0.1944960206747055, 0.43910735845565796, 0.2516174614429474, 0.0974109023809433, 0.01736820675432682], [0.27860546112060547, 0.3907899260520935, 0.19117005169391632, 0.12780047953128815, 0.011634032242000103], [0.28625258803367615, 0.40517696738243103, 0.22591562569141388, 0.0728842243552208, 0.009770586155354977], [0.25225451588630676, 0.44868311285972595, 0.20989449322223663, 0.0753062441945076, 0.013861780986189842], [0.269386887550354, 0.5068284273147583, 0.13815969228744507, 0.07188287377357483, 0.013742079958319664], [0.18960410356521606, 0.5119536519050598, 0.22739817202091217, 0.05930910259485245, 0.011735029518604279], [0.184965118765831, 0.5414474606513977, 0.20119622349739075, 0.05893223360180855, 0.013458923436701298], [0.3423745632171631, 0.3450186252593994, 0.1692543774843216, 0.13110201060771942, 0.012250385247170925], [0.2849532961845398, 0.3934303820133209, 0.19131901860237122, 0.12047724425792694, 0.009820078499615192], [0.3149425983428955, 0.3606830835342407, 0.20371250808238983, 0.11041723936796188, 0.010244455188512802], [0.24830807745456696, 0.42863669991493225, 0.22043776512145996, 0.09227458387613297, 0.010342855006456375], [0.17980462312698364, 0.550280749797821, 0.20927013456821442, 0.04954380914568901, 0.011100647039711475], [0.2536843419075012, 0.42593619227409363, 0.1945413500070572, 0.10745564848184586, 0.01838233321905136], [0.22639428079128265, 0.4842691421508789, 0.20471517741680145, 0.07460623979568481, 0.010015169158577919], [0.2946597635746002, 0.3061562776565552, 0.179568350315094, 0.2081945240497589, 0.01142104435712099], [0.24643297493457794, 0.3975923955440521, 0.2039966881275177, 0.14073511958122253, 0.011242827400565147], [0.1951664835214615, 0.49433082342147827, 0.1620129495859146, 0.1351759284734726, 0.013313846662640572], [0.20072944462299347, 0.4880675971508026, 0.18898344039916992, 0.10967519879341125, 0.012544317170977592], [0.28979888558387756, 0.4153948426246643, 0.16227948665618896, 0.12345439195632935, 0.009072412736713886], [0.2139434963464737, 0.42401549220085144, 0.19222740828990936, 0.15503865480422974, 0.014775016345083714], [0.1607702672481537, 0.609112560749054, 0.1701957881450653, 0.04420926049351692, 0.01571219600737095], [0.18919095396995544, 0.5111280679702759, 0.22197279334068298, 0.06613731384277344, 0.01157087367027998], [0.2294551283121109, 0.5124030709266663, 0.17108382284641266, 0.07645066827535629, 0.01060736458748579], [0.18850475549697876, 0.5827223658561707, 0.16357925534248352, 0.054021306335926056, 0.011172402650117874], [0.242147758603096, 0.30079346895217896, 0.2379915863275528, 0.20565328001976013, 0.01341391820460558], [0.1854541003704071, 0.5282389521598816, 0.2131291776895523, 0.060015447437763214, 0.013162381015717983], [0.16045448184013367, 0.5830695033073425, 0.15395662188529968, 0.08787278831005096, 0.014646559953689575], [0.17308346927165985, 0.5388087034225464, 0.21520310640335083, 0.058527205139398575, 0.014377541840076447], [0.27392932772636414, 0.3608730733394623, 0.21837829053401947, 0.1348503679037094, 0.011968976818025112], [0.25799739360809326, 0.38441187143325806, 0.21340163052082062, 0.13400813937187195, 0.010180939920246601], [0.2037467360496521, 0.5154901742935181, 0.2065819799900055, 0.06055958569049835, 0.013621535152196884], [0.24518230557441711, 0.41727501153945923, 0.22293084859848022, 0.10245370119810104, 0.012158110737800598], [0.24173125624656677, 0.4252520203590393, 0.23677335679531097, 0.08648159354925156, 0.009761747904121876], [0.24808166921138763, 0.42107146978378296, 0.18606677651405334, 0.13381710648536682, 0.01096292957663536], [0.2949393391609192, 0.3302038013935089, 0.24018175899982452, 0.12493246793746948, 0.009742596186697483], [0.18634898960590363, 0.5002403259277344, 0.2452385425567627, 0.05822071433067322, 0.00995146669447422], [0.19507057964801788, 0.5200413465499878, 0.19613631069660187, 0.07638998329639435, 0.01236171554774046], [0.22029443085193634, 0.5137391090393066, 0.15665461122989655, 0.09872709214687347, 0.010584810748696327], [0.2486160844564438, 0.4919328987598419, 0.16959214210510254, 0.0806800052523613, 0.009178955107927322], [0.27676934003829956, 0.44326990842819214, 0.1677374541759491, 0.09882165491580963, 0.013401653617620468], [0.28359976410865784, 0.3946605920791626, 0.15400034189224243, 0.15570694208145142, 0.012032278813421726], [0.2527058720588684, 0.346390962600708, 0.1522209346294403, 0.22854655981063843, 0.020135700702667236], [0.19130690395832062, 0.5279681086540222, 0.21129462122917175, 0.05663827806711197, 0.012792020104825497], [0.22497564554214478, 0.4922846257686615, 0.20121924579143524, 0.0712260901927948, 0.010294337756931782], [0.1712089627981186, 0.5672863721847534, 0.15437006950378418, 0.09288342297077179, 0.014251122251152992], [0.1598331332206726, 0.5404258370399475, 0.23056189715862274, 0.0562586709856987, 0.012920503504574299], [0.2571563422679901, 0.4750993549823761, 0.19065438210964203, 0.06634702533483505, 0.010742858052253723], [0.2306264042854309, 0.40744253993034363, 0.20274576544761658, 0.14906860888004303, 0.010116751305758953], [0.16536903381347656, 0.5969513654708862, 0.161348357796669, 0.061165425926446915, 0.015165873803198338], [0.21097570657730103, 0.4813011884689331, 0.23786813020706177, 0.05704865977168083, 0.012806307524442673]]\n",
      "1.384881854057312\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.4750\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.34      0.40        64\n",
      "           1       0.70      0.67      0.68        63\n",
      "           2       0.39      0.22      0.28        41\n",
      "           3       0.31      0.79      0.44        28\n",
      "           4       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.47       200\n",
      "   macro avg       0.38      0.40      0.36       200\n",
      "weighted avg       0.50      0.47      0.46       200\n",
      "\n",
      "[[0.08594880253076553, 0.43285873532295227, 0.4494163990020752, 0.02597496286034584, 0.005801109131425619], [0.3658751845359802, 0.34668415784835815, 0.10276000946760178, 0.17659853398799896, 0.008082020096480846], [0.26808393001556396, 0.03410424664616585, 0.0709596574306488, 0.612450361251831, 0.01440175250172615], [0.4376979470252991, 0.1321866512298584, 0.17665217816829681, 0.240957111120224, 0.01250605657696724], [0.1543472856283188, 0.5117879509925842, 0.25388336181640625, 0.07295703887939453, 0.007024458609521389], [0.26481762528419495, 0.1004929393529892, 0.32169297337532043, 0.30083057284355164, 0.0121658556163311], [0.26133984327316284, 0.271559476852417, 0.4040982723236084, 0.05720335617661476, 0.00579905416816473], [0.31137335300445557, 0.18235309422016144, 0.13934865593910217, 0.35479792952537537, 0.012126930058002472], [0.264527827501297, 0.22055476903915405, 0.4478507339954376, 0.060178883373737335, 0.006887740455567837], [0.4016868770122528, 0.1333657056093216, 0.14610914885997772, 0.30995646119117737, 0.008881759829819202], [0.29629507660865784, 0.3202498257160187, 0.33122748136520386, 0.04597647860646248, 0.006251201499253511], [0.38885435461997986, 0.14823821187019348, 0.10099276900291443, 0.3485969305038452, 0.013317752629518509], [0.24785470962524414, 0.0431845597922802, 0.15408794581890106, 0.5417049527168274, 0.013167872093617916], [0.3673068881034851, 0.13004052639007568, 0.08310148864984512, 0.4083056151866913, 0.011245416477322578], [0.2757470905780792, 0.1015002429485321, 0.22879275679588318, 0.3806558847427368, 0.013303983956575394], [0.2539331912994385, 0.03232206404209137, 0.0987708643078804, 0.6019678711891174, 0.013005969114601612], [0.2553452253341675, 0.18210801482200623, 0.15029262006282806, 0.39577516913414, 0.01647900976240635], [0.25785472989082336, 0.044915493577718735, 0.09399152547121048, 0.5916638374328613, 0.011574486270546913], [0.20302236080169678, 0.3445344567298889, 0.3678050637245178, 0.07764139771461487, 0.006996767595410347], [0.33852386474609375, 0.05141172185540199, 0.10552570968866348, 0.4945671856403351, 0.00997164100408554], [0.2646021842956543, 0.10398445278406143, 0.08192907273769379, 0.540092408657074, 0.009391889907419682], [0.329179972410202, 0.3135392963886261, 0.20798783004283905, 0.14237424731254578, 0.006918607745319605], [0.24944154918193817, 0.04713825881481171, 0.061956148594617844, 0.629835307598114, 0.011628713458776474], [0.255971223115921, 0.3464917838573456, 0.31819477677345276, 0.07114630192518234, 0.008195946924388409], [0.26833584904670715, 0.08480452746152878, 0.10919919610023499, 0.5197447538375854, 0.017915578559041023], [0.1246744766831398, 0.7031157612800598, 0.14466752111911774, 0.0216731708496809, 0.005869140382856131], [0.2556793689727783, 0.32355502247810364, 0.37118998169898987, 0.042892903089523315, 0.0066826618276536465], [0.33857598900794983, 0.2033664435148239, 0.28637364506721497, 0.16347554326057434, 0.008208400569856167], [0.3151262104511261, 0.14932218194007874, 0.3404703438282013, 0.18568450212478638, 0.00939677469432354], [0.25250816345214844, 0.0463721863925457, 0.05553831160068512, 0.6302904486656189, 0.015290860086679459], [0.3525561988353729, 0.07876283675432205, 0.13194432854652405, 0.4250750243663788, 0.011661703698337078], [0.37266576290130615, 0.1359623521566391, 0.27428704500198364, 0.20800025761127472, 0.009084605611860752], [0.13319407403469086, 0.5284615755081177, 0.3031364977359772, 0.02800437994301319, 0.007203548215329647], [0.21095897257328033, 0.2735688090324402, 0.4053909480571747, 0.10229261219501495, 0.0077886395156383514], [0.14531227946281433, 0.5826996564865112, 0.22115926444530487, 0.04411055147647858, 0.006718290504068136], [0.277093768119812, 0.06432405859231949, 0.12762388586997986, 0.5200906991958618, 0.01086764968931675], [0.12672114372253418, 0.6192739605903625, 0.2122786045074463, 0.036522027105093, 0.00520424684509635], [0.3978578746318817, 0.15085448324680328, 0.0965491235256195, 0.3456941843032837, 0.009044263511896133], [0.3129590153694153, 0.09255770593881607, 0.07397519797086716, 0.5095095634460449, 0.010998559184372425], [0.08996164798736572, 0.6280496716499329, 0.24991606175899506, 0.02680078148841858, 0.00527184596285224], [0.42047595977783203, 0.08091072738170624, 0.0591435432434082, 0.42406514286994934, 0.015404675155878067], [0.29516157507896423, 0.19401679933071136, 0.3190990388393402, 0.17788894474506378, 0.013833672739565372], [0.3637002408504486, 0.29904863238334656, 0.20645290613174438, 0.12450961768627167, 0.006288600619882345], [0.2960980534553528, 0.17788559198379517, 0.24462763965129852, 0.27154216170310974, 0.009846463799476624], [0.11419294029474258, 0.7046987414360046, 0.1317642480134964, 0.0378020741045475, 0.011542022228240967], [0.18159762024879456, 0.38985708355903625, 0.23194195330142975, 0.18587566912174225, 0.010727648623287678], [0.13409696519374847, 0.5354220867156982, 0.28538045287132263, 0.03882322087883949, 0.006277368403971195], [0.16729329526424408, 0.6490867733955383, 0.12921670079231262, 0.045452315360307693, 0.008950936608016491], [0.15978862345218658, 0.5247930288314819, 0.2179424911737442, 0.09005071222782135, 0.007425100542604923], [0.2688586711883545, 0.2438240349292755, 0.3176494538784027, 0.16161662340164185, 0.008051197975873947], [0.2498590648174286, 0.6060656905174255, 0.10862872004508972, 0.02825300581753254, 0.00719350203871727], [0.31828489899635315, 0.327216774225235, 0.28028300404548645, 0.06766411662101746, 0.006551178637892008], [0.09345684945583344, 0.7665145993232727, 0.10075734555721283, 0.03139153867959976, 0.007879558019340038], [0.1882258504629135, 0.4938870370388031, 0.2437012642621994, 0.06663130223751068, 0.007554435636848211], [0.22783249616622925, 0.07904189825057983, 0.3070000112056732, 0.36827555298805237, 0.017850078642368317], [0.13512222468852997, 0.5387153625488281, 0.2809546887874603, 0.03818194195628166, 0.00702586118131876], [0.3047700524330139, 0.1274891197681427, 0.2431502491235733, 0.3153502941131592, 0.009240303188562393], [0.32090112566947937, 0.07356322556734085, 0.12809257209300995, 0.46524110436439514, 0.012201962061226368], [0.07626059651374817, 0.7716374397277832, 0.09941510111093521, 0.04179299622774124, 0.010893907397985458], [0.3453049659729004, 0.2644951343536377, 0.21858195960521698, 0.16218619048595428, 0.009431744925677776], [0.2072886973619461, 0.34817859530448914, 0.22920720279216766, 0.20429982244968414, 0.011025638319551945], [0.38009920716285706, 0.08471979945898056, 0.08950114995241165, 0.4354168176651001, 0.010262982919812202], [0.14254851639270782, 0.028415337204933167, 0.09449591487646103, 0.7177329063415527, 0.016807328909635544], [0.30106833577156067, 0.3817909359931946, 0.1684807986021042, 0.13893671333789825, 0.009723336435854435], [0.296880304813385, 0.10045485198497772, 0.19212952256202698, 0.3972511291503906, 0.013284189626574516], [0.4489835202693939, 0.18296103179454803, 0.1478474736213684, 0.2092110514640808, 0.010996965691447258], [0.24676673114299774, 0.2610052227973938, 0.3989047706127167, 0.08445946872234344, 0.008863871917128563], [0.24298326671123505, 0.13041742146015167, 0.18276648223400116, 0.42619431018829346, 0.017638403922319412], [0.3321426212787628, 0.18914972245693207, 0.21374863386154175, 0.2562524378299713, 0.008706623688340187], [0.2855682969093323, 0.31712809205055237, 0.1931370049715042, 0.19473443925380707, 0.009432146325707436], [0.37120288610458374, 0.4284258782863617, 0.12220626324415207, 0.07162971049547195, 0.006535337306559086], [0.3900444209575653, 0.3087116479873657, 0.1333094835281372, 0.15882974863052368, 0.00910473708063364], [0.3596097528934479, 0.20624499022960663, 0.16599899530410767, 0.25786498188972473, 0.010281318798661232], [0.38374415040016174, 0.34765204787254333, 0.14881913363933563, 0.10898827016353607, 0.010796464048326015], [0.33035165071487427, 0.22644203901290894, 0.2093193233013153, 0.22531293332576752, 0.008573992177844048], [0.1256922036409378, 0.6289073824882507, 0.16220325231552124, 0.07295721024274826, 0.01023996900767088], [0.42643624544143677, 0.10348407179117203, 0.16282464563846588, 0.29892367124557495, 0.008331355638802052], [0.19025114178657532, 0.5743381977081299, 0.18168336153030396, 0.04627154394984245, 0.0074557168409228325], [0.3152524530887604, 0.10700530558824539, 0.15960238873958588, 0.40329599380493164, 0.01484399102628231], [0.1625828891992569, 0.5936049818992615, 0.18836738169193268, 0.04707189276814461, 0.008372796699404716], [0.2626485824584961, 0.06034618243575096, 0.2627582848072052, 0.39951270818710327, 0.014734294265508652], [0.14196889102458954, 0.028543410822749138, 0.07060660421848297, 0.7408599853515625, 0.018021075055003166], [0.16284166276454926, 0.6253899335861206, 0.15686146914958954, 0.04686491936445236, 0.008042005822062492], [0.34376317262649536, 0.18806873261928558, 0.21562528610229492, 0.24413885176181793, 0.008403941057622433], [0.31831395626068115, 0.07119987159967422, 0.0682021975517273, 0.5312402844429016, 0.011043701320886612], [0.22738797962665558, 0.5629958510398865, 0.1236182376742363, 0.07863061875104904, 0.007367280777543783], [0.30112993717193604, 0.04651864618062973, 0.06859850138425827, 0.571025013923645, 0.012727903202176094], [0.4063822031021118, 0.17615000903606415, 0.1886642873287201, 0.21771836280822754, 0.011085201054811478], [0.3012067675590515, 0.3683837950229645, 0.1448434442281723, 0.1717844158411026, 0.013781639747321606], [0.526061475276947, 0.18812870979309082, 0.1296761929988861, 0.14687290787696838, 0.009260805323719978], [0.1928095519542694, 0.07372322678565979, 0.24310247600078583, 0.477500319480896, 0.012864493764936924], [0.426857590675354, 0.08416036516427994, 0.07442758232355118, 0.40206173062324524, 0.012492737732827663], [0.2702529728412628, 0.06772854179143906, 0.11272339522838593, 0.532521665096283, 0.016773397102952003], [0.24513958394527435, 0.16298259794712067, 0.13628095388412476, 0.4441387355327606, 0.011458185501396656], [0.339997261762619, 0.0630747601389885, 0.05885350704193115, 0.5273900628089905, 0.010684454813599586], [0.30372393131256104, 0.46642521023750305, 0.18866127729415894, 0.034599341452121735, 0.006590179167687893], [0.20626340806484222, 0.09269476681947708, 0.1315455436706543, 0.558600664138794, 0.010895557701587677], [0.2963624596595764, 0.36217203736305237, 0.29247790575027466, 0.04340061917901039, 0.00558703625574708], [0.43670332431793213, 0.29945313930511475, 0.1926245540380478, 0.06548440456390381, 0.00573451304808259], [0.2082505226135254, 0.03069349005818367, 0.10833076387643814, 0.6353940367698669, 0.017331155017018318], [0.2328958809375763, 0.5357356071472168, 0.18239524960517883, 0.0392732098698616, 0.009700067341327667], [0.20475952327251434, 0.5104100704193115, 0.23820970952510834, 0.041480377316474915, 0.005140351131558418], [0.3309086561203003, 0.10804042220115662, 0.12486898899078369, 0.4279273748397827, 0.008254576474428177], [0.23082290589809418, 0.42677876353263855, 0.14863896369934082, 0.178788959980011, 0.014970442280173302], [0.157037153840065, 0.4985250234603882, 0.2708406150341034, 0.06262506544589996, 0.0109722213819623], [0.3900848627090454, 0.27457302808761597, 0.18416985869407654, 0.14378461241722107, 0.0073876637034118176], [0.23519305884838104, 0.3617224395275116, 0.28452011942863464, 0.10986478626728058, 0.008699683472514153], [0.4042508602142334, 0.22386838495731354, 0.3164081275463104, 0.047208961099386215, 0.008263658732175827], [0.18749867379665375, 0.501420795917511, 0.2027641087770462, 0.09897978603839874, 0.00933668203651905], [0.3794063925743103, 0.1453111618757248, 0.33373796939849854, 0.13309016823768616, 0.008454248309135437], [0.12725384533405304, 0.334512859582901, 0.46524545550346375, 0.06530563533306122, 0.007682229392230511], [0.14491049945354462, 0.024683650583028793, 0.0844804123044014, 0.7254833579063416, 0.020442038774490356], [0.3379557728767395, 0.14315278828144073, 0.25291907787323, 0.25533875823020935, 0.010633519850671291], [0.28554192185401917, 0.4176138639450073, 0.19800354540348053, 0.091203972697258, 0.007636663503944874], [0.15928378701210022, 0.037158381193876266, 0.08335275948047638, 0.7038207054138184, 0.016384417191147804], [0.2537868618965149, 0.27409255504608154, 0.35201743245124817, 0.11337859183549881, 0.006724537815898657], [0.22655437886714935, 0.051770783960819244, 0.07630210369825363, 0.6307160258293152, 0.014656665734946728], [0.32175490260124207, 0.18424096703529358, 0.3072535991668701, 0.17560335993766785, 0.011147151701152325], [0.17960144579410553, 0.4860183596611023, 0.23052027821540833, 0.09716883301734924, 0.006691001355648041], [0.21176326274871826, 0.05907931923866272, 0.0812128558754921, 0.6360120177268982, 0.011932522989809513], [0.26781657338142395, 0.09111477434635162, 0.16861040890216827, 0.44914984703063965, 0.02330849878489971], [0.19033993780612946, 0.5018563270568848, 0.2779424786567688, 0.02312195487320423, 0.006739391945302486], [0.21384988725185394, 0.5668612122535706, 0.15691451728343964, 0.054200030863285065, 0.008174424059689045], [0.2520066797733307, 0.1161336824297905, 0.15678498148918152, 0.45864787697792053, 0.016426753252744675], [0.12127388268709183, 0.698794424533844, 0.1543625295162201, 0.01923437975347042, 0.006334756501019001], [0.23730751872062683, 0.11430978029966354, 0.15494921803474426, 0.4830115735530853, 0.010421919636428356], [0.19471824169158936, 0.46820124983787537, 0.28095629811286926, 0.04822808876633644, 0.007896210998296738], [0.2819392681121826, 0.041400354355573654, 0.08297010511159897, 0.5795859694480896, 0.014104302041232586], [0.13415783643722534, 0.3362484872341156, 0.49418550729751587, 0.028686825186014175, 0.006721325684338808], [0.3008212149143219, 0.33931493759155273, 0.2551133334636688, 0.0953969657421112, 0.009353510104119778], [0.2892507016658783, 0.09262432903051376, 0.3636644780635834, 0.24136748909950256, 0.013093038462102413], [0.1621178686618805, 0.03466781973838806, 0.11215721070766449, 0.6653501987457275, 0.025706930086016655], [0.12013929337263107, 0.686888575553894, 0.14524395763874054, 0.04085754230618477, 0.006870628334581852], [0.22173266112804413, 0.03444128483533859, 0.060561653226614, 0.671075701713562, 0.01218872144818306], [0.1967233121395111, 0.0449807308614254, 0.09878341108560562, 0.6450819373130798, 0.014430589973926544], [0.29629454016685486, 0.14901793003082275, 0.20778970420360565, 0.3365117013454437, 0.01038617268204689], [0.281850665807724, 0.2837119400501251, 0.12841825187206268, 0.2971682846546173, 0.008850917220115662], [0.0821649357676506, 0.755641758441925, 0.12593263387680054, 0.0261811725795269, 0.010079528205096722], [0.26071858406066895, 0.15829956531524658, 0.17093203961849213, 0.400795578956604, 0.009254222735762596], [0.3768368661403656, 0.17189809679985046, 0.19975049793720245, 0.24000881612300873, 0.011505750007927418], [0.2583813965320587, 0.05842636525630951, 0.12128493934869766, 0.5499849319458008, 0.0119223827496171], [0.0877159982919693, 0.5991799831390381, 0.21369431912899017, 0.08570264279842377, 0.013706973753869534], [0.1903703212738037, 0.49602967500686646, 0.23098044097423553, 0.07573247700929642, 0.006886974908411503], [0.1112842783331871, 0.7163663506507874, 0.1186453178524971, 0.043781232088804245, 0.009922748431563377], [0.34040969610214233, 0.10295937955379486, 0.11473404616117477, 0.43019187450408936, 0.011705126613378525], [0.31592485308647156, 0.14903275668621063, 0.08994951099157333, 0.4328169524669647, 0.012276014313101768], [0.3256100118160248, 0.09035705029964447, 0.1338571161031723, 0.4408954977989197, 0.009280265308916569], [0.3047640323638916, 0.3105561137199402, 0.17574234306812286, 0.20041222870349884, 0.00852531660348177], [0.10281552374362946, 0.5435714721679688, 0.3312082886695862, 0.016102656722068787, 0.006302079185843468], [0.2692263126373291, 0.07808090001344681, 0.0777164101600647, 0.559044361114502, 0.015931976959109306], [0.22356364130973816, 0.23368613421916962, 0.38309335708618164, 0.14315080642700195, 0.016506042331457138], [0.3793322741985321, 0.1777837574481964, 0.1624826341867447, 0.2687477469444275, 0.011653658002614975], [0.40948906540870667, 0.1795293539762497, 0.34346795082092285, 0.061402492225170135, 0.006111158058047295], [0.4626087248325348, 0.24006395041942596, 0.17418543994426727, 0.11353395134210587, 0.009608028456568718], [0.4680311679840088, 0.30191439390182495, 0.14021435379981995, 0.08033781498670578, 0.009502213448286057], [0.18944606184959412, 0.4237115681171417, 0.32074838876724243, 0.060485612601041794, 0.005608321633189917], [0.2251388281583786, 0.3832119405269623, 0.24603746831417084, 0.1343672275543213, 0.011244582012295723], [0.42739230394363403, 0.084604911506176, 0.10221991688013077, 0.37426289916038513, 0.01152000855654478], [0.27380648255348206, 0.05864274874329567, 0.10481729358434677, 0.5477165579795837, 0.01501692458987236], [0.4961617588996887, 0.12411481887102127, 0.1672331839799881, 0.20366674661636353, 0.008823433890938759], [0.3910544812679291, 0.10874389111995697, 0.1962316334247589, 0.2958313226699829, 0.008138756267726421], [0.2019578516483307, 0.36890709400177, 0.3902718722820282, 0.033770494163036346, 0.0050927214324474335], [0.372996062040329, 0.26386669278144836, 0.16123834252357483, 0.18267005681991577, 0.019228914752602577], [0.30111196637153625, 0.10918960720300674, 0.2056243121623993, 0.37131884694099426, 0.012755336239933968], [0.24312430620193481, 0.036566030234098434, 0.08384858071804047, 0.6231474876403809, 0.013313597068190575], [0.28499847650527954, 0.14574559032917023, 0.17591269314289093, 0.38383665680885315, 0.00950654223561287], [0.19170556962490082, 0.22134582698345184, 0.17520028352737427, 0.39759138226509094, 0.014156851917505264], [0.23370280861854553, 0.1344946026802063, 0.11386910080909729, 0.506420373916626, 0.011513087898492813], [0.33592459559440613, 0.07724343240261078, 0.10248398780822754, 0.4746576249599457, 0.00969037227332592], [0.1822010725736618, 0.11835198104381561, 0.1641668826341629, 0.5173839926719666, 0.0178961381316185], [0.1449434608221054, 0.6737958788871765, 0.14823131263256073, 0.02503995969891548, 0.007989327423274517], [0.17487424612045288, 0.41128072142601013, 0.3379208445549011, 0.06950430572032928, 0.006419884506613016], [0.40256303548812866, 0.17648707330226898, 0.09694115072488785, 0.3116215169429779, 0.012387119233608246], [0.1611800342798233, 0.6392793655395508, 0.15941768884658813, 0.033925626426935196, 0.006197295617312193], [0.15164732933044434, 0.03869640454649925, 0.10422214865684509, 0.6855745315551758, 0.01985957659780979], [0.20670801401138306, 0.34192806482315063, 0.3493606746196747, 0.09221108257770538, 0.00979224219918251], [0.18125075101852417, 0.4282667338848114, 0.20043358206748962, 0.17916452884674072, 0.010884425602853298], [0.1377340704202652, 0.5792765617370605, 0.23649601638317108, 0.03875439986586571, 0.007739019580185413], [0.2697169780731201, 0.047872256487607956, 0.08142184466123581, 0.5844494104385376, 0.016539547592401505], [0.25293463468551636, 0.15323230624198914, 0.29119715094566345, 0.2905769646167755, 0.012058904394507408], [0.2848702669143677, 0.2679464817047119, 0.28142625093460083, 0.15564769506454468, 0.01010922621935606], [0.2825247645378113, 0.14362788200378418, 0.28143468499183655, 0.2823263108730316, 0.010086366906762123], [0.35542553663253784, 0.12377661466598511, 0.251228928565979, 0.26114314794540405, 0.008425736799836159], [0.17756277322769165, 0.03682785853743553, 0.0882105752825737, 0.6849409937858582, 0.01245779450982809], [0.36256739497184753, 0.06578321009874344, 0.20627792179584503, 0.35599392652511597, 0.00937753077596426], [0.1691340059041977, 0.3610883057117462, 0.4213104546070099, 0.04278494045138359, 0.00568231800571084], [0.2542428970336914, 0.25285616517066956, 0.16857486963272095, 0.3122357726097107, 0.012090325355529785], [0.30377307534217834, 0.2300768792629242, 0.11466037482023239, 0.3420429825782776, 0.009446712210774422], [0.534959614276886, 0.13805469870567322, 0.09194255620241165, 0.226835235953331, 0.008207842707633972], [0.4520186483860016, 0.1497829556465149, 0.10593512654304504, 0.27743208408355713, 0.014831176027655602], [0.2682550549507141, 0.04768040403723717, 0.04640991613268852, 0.6244292855262756, 0.013225355185568333], [0.22440241277217865, 0.09573956578969955, 0.09833753854036331, 0.5576854348182678, 0.023835081607103348], [0.17815211415290833, 0.3280552625656128, 0.44156020879745483, 0.04557044804096222, 0.0066619510762393475], [0.34727710485458374, 0.21416021883487701, 0.18019898235797882, 0.24833644926548004, 0.010027246549725533], [0.16293472051620483, 0.6138185858726501, 0.11495468765497208, 0.09455586969852448, 0.013736187480390072], [0.1119021624326706, 0.5153319239616394, 0.31524479389190674, 0.050360649824142456, 0.007160401903092861], [0.3974002003669739, 0.22622570395469666, 0.15657135844230652, 0.2103145271539688, 0.009488222189247608], [0.2021065354347229, 0.09333813935518265, 0.09734731912612915, 0.5954622030258179, 0.011745812371373177], [0.2235659956932068, 0.5505472421646118, 0.10246312618255615, 0.1136723980307579, 0.009751197881996632], [0.2992929518222809, 0.2221519947052002, 0.36171478033065796, 0.10865695029497147, 0.008183264173567295]]\n",
      "1.1567605659365654\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.56      0.53        64\n",
      "           1       0.52      0.79      0.63        63\n",
      "           2       0.50      0.17      0.25        41\n",
      "           3       0.47      0.32      0.38        28\n",
      "           4       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.51       200\n",
      "   macro avg       0.40      0.37      0.36       200\n",
      "weighted avg       0.50      0.51      0.47       200\n",
      "\n",
      "[[0.028078876435756683, 0.5598620772361755, 0.40069371461868286, 0.006109269335865974, 0.0052561028860509396], [0.21663683652877808, 0.6588444113731384, 0.09094128757715225, 0.027989685535430908, 0.005587853025645018], [0.45649367570877075, 0.023525508120656013, 0.03464105725288391, 0.4676399230957031, 0.01769985258579254], [0.48350146412849426, 0.20423635840415955, 0.2505841851234436, 0.051915980875492096, 0.009762040339410305], [0.05368096008896828, 0.730087161064148, 0.19915783405303955, 0.01155016291886568, 0.0055239200592041016], [0.16255657374858856, 0.4212726354598999, 0.39014676213264465, 0.021079666912555695, 0.004944282583892345], [0.12979865074157715, 0.5869295597076416, 0.2672097980976105, 0.011184312403202057, 0.004877682775259018], [0.2894105613231659, 0.18325889110565186, 0.2654261887073517, 0.25169509649276733, 0.01020920928567648], [0.12214457243680954, 0.37828707695007324, 0.47934600710868835, 0.0132113266736269, 0.0070110345259308815], [0.5972679257392883, 0.10111138224601746, 0.14178608357906342, 0.15279802680015564, 0.007036549039185047], [0.20404377579689026, 0.5251904129981995, 0.2547997534275055, 0.010538795962929726, 0.005427243188023567], [0.5152924060821533, 0.32081523537635803, 0.07161635160446167, 0.07700494676828384, 0.015271183103322983], [0.3417300581932068, 0.029169928282499313, 0.1503576636314392, 0.4686782658100128, 0.010064119473099709], [0.603967010974884, 0.10416675359010696, 0.05492342263460159, 0.2233080267906189, 0.013634802773594856], [0.46531012654304504, 0.1588083654642105, 0.17567914724349976, 0.19070932269096375, 0.009493131190538406], [0.4547336995601654, 0.023043528199195862, 0.06259282678365707, 0.4471297264099121, 0.01250014454126358], [0.26362118124961853, 0.42591699957847595, 0.1645679771900177, 0.13402661681175232, 0.01186726987361908], [0.5486156940460205, 0.04468098282814026, 0.07071959227323532, 0.3266543745994568, 0.009329250082373619], [0.12545861303806305, 0.41016361117362976, 0.44160598516464233, 0.019047359004616737, 0.003724323585629463], [0.6930106282234192, 0.053749408572912216, 0.10836133360862732, 0.13870294392108917, 0.0061757490038871765], [0.4886052906513214, 0.27777203917503357, 0.05475512892007828, 0.16956330835819244, 0.009304257109761238], [0.18747703731060028, 0.6112483739852905, 0.176622211933136, 0.019856799393892288, 0.004795552231371403], [0.4966391623020172, 0.07136569917201996, 0.06235320493578911, 0.3586635887622833, 0.010978366248309612], [0.10107044875621796, 0.5746133327484131, 0.30546435713768005, 0.013349711894989014, 0.005502196028828621], [0.4716646671295166, 0.22044706344604492, 0.11233039945363998, 0.17662324011325836, 0.018934594467282295], [0.0367751307785511, 0.8777920007705688, 0.0758778303861618, 0.004272617865353823, 0.0052824863232672215], [0.10209589451551437, 0.7587065100669861, 0.12750598788261414, 0.005679482594132423, 0.006012168247252703], [0.30908480286598206, 0.5088797211647034, 0.1396166831254959, 0.035584840923547745, 0.006834021303802729], [0.13981997966766357, 0.6594401597976685, 0.1847088485956192, 0.009794437326490879, 0.00623653270304203], [0.48536017537117004, 0.047433797270059586, 0.04160575941205025, 0.40636226534843445, 0.019237985834479332], [0.6894757747650146, 0.1102987602353096, 0.09392000734806061, 0.09952962398529053, 0.006775714922696352], [0.5571146607398987, 0.1793353408575058, 0.21244366466999054, 0.04665323346853256, 0.00445306533947587], [0.04006544500589371, 0.8025193810462952, 0.14446702599525452, 0.006012747995555401, 0.006935397163033485], [0.10795459151268005, 0.3840480446815491, 0.4864475429058075, 0.016996296122670174, 0.00455353781580925], [0.034516461193561554, 0.7778189778327942, 0.1781810075044632, 0.005917176604270935, 0.003566526807844639], [0.3827078640460968, 0.03509934991598129, 0.1503015160560608, 0.42169952392578125, 0.010191716253757477], [0.03692355006933212, 0.8224443197250366, 0.13016900420188904, 0.006513411179184914, 0.003949775360524654], [0.2754002511501312, 0.5988355278968811, 0.08903545886278152, 0.031198646873235703, 0.005530152469873428], [0.6294947266578674, 0.12429111450910568, 0.05370302498340607, 0.181678906083107, 0.010832252912223339], [0.027583440765738487, 0.7340416312217712, 0.2278493493795395, 0.006047504022717476, 0.004478054121136665], [0.7148840427398682, 0.06008294224739075, 0.03331761807203293, 0.1766977310180664, 0.015017672441899776], [0.4953018128871918, 0.1728687584400177, 0.2447482794523239, 0.07657874375581741, 0.010502352379262447], [0.2045077383518219, 0.5125858187675476, 0.25557270646095276, 0.02232493832707405, 0.005008722189813852], [0.372101366519928, 0.19542478024959564, 0.34259700775146484, 0.0843198224902153, 0.005557000637054443], [0.042758967727422714, 0.8303964734077454, 0.10653884708881378, 0.012184654362499714, 0.008121069520711899], [0.059256818145513535, 0.7833647131919861, 0.1330585926771164, 0.01917334273457527, 0.005146522540599108], [0.0508255660533905, 0.6691113114356995, 0.2687053084373474, 0.0076614259742200375, 0.003696402767673135], [0.07260207086801529, 0.8319715857505798, 0.07760012149810791, 0.010151516646146774, 0.007674651686102152], [0.05663770064711571, 0.6988193988800049, 0.2235523760318756, 0.016240131109952927, 0.004750419408082962], [0.2445743829011917, 0.42507612705230713, 0.29442355036735535, 0.03083285316824913, 0.00509315961971879], [0.09363667666912079, 0.8414038419723511, 0.05340626463294029, 0.005817512981593609, 0.005735593847930431], [0.16148971021175385, 0.5358400344848633, 0.28464019298553467, 0.013148253783583641, 0.004881787579506636], [0.029123125597834587, 0.8781610727310181, 0.0787794291973114, 0.008084306493401527, 0.005852095782756805], [0.06391110271215439, 0.7110812664031982, 0.2086021602153778, 0.010874247178435326, 0.0055312346667051315], [0.1590234935283661, 0.20842304825782776, 0.600511908531189, 0.02690478414297104, 0.005136668216437101], [0.038283850997686386, 0.7836252450942993, 0.16686183214187622, 0.006747622042894363, 0.004481468815356493], [0.3254487216472626, 0.2073899358510971, 0.38821181654930115, 0.07238107919692993, 0.006568447221070528], [0.6186593770980835, 0.056267254054546356, 0.07713675498962402, 0.2395031899213791, 0.008433443494141102], [0.023808002471923828, 0.8693349957466125, 0.08841045945882797, 0.011623511090874672, 0.006822987459599972], [0.22190234065055847, 0.5604392886161804, 0.1850176453590393, 0.024249786511063576, 0.008390873670578003], [0.1256192922592163, 0.4542970061302185, 0.35035601258277893, 0.0618036687374115, 0.00792410783469677], [0.5197804570198059, 0.04126874729990959, 0.06038406118750572, 0.3685963749885559, 0.009970408864319324], [0.12476649880409241, 0.015092403627932072, 0.11263957619667053, 0.7332848906517029, 0.014216629788279533], [0.23758885264396667, 0.552054226398468, 0.1635858118534088, 0.03838604688644409, 0.008385122753679752], [0.38372206687927246, 0.10814901441335678, 0.33439895510673523, 0.16366060078144073, 0.010069412179291248], [0.5587518215179443, 0.12837229669094086, 0.12056255340576172, 0.17529700696468353, 0.0170162171125412], [0.17177221179008484, 0.5307660698890686, 0.27703025937080383, 0.013585582375526428, 0.006845924071967602], [0.26872682571411133, 0.12568393349647522, 0.30475494265556335, 0.2864076793193817, 0.0144265815615654], [0.22912725806236267, 0.5815735459327698, 0.16501237452030182, 0.01886877417564392, 0.00541804451495409], [0.24253463745117188, 0.3891468346118927, 0.25320038199424744, 0.10553571581840515, 0.009582341648638248], [0.16234606504440308, 0.7699899077415466, 0.05113901570439339, 0.010605055838823318, 0.005919965449720621], [0.3124680817127228, 0.5523207783699036, 0.08606672286987305, 0.04088997468352318, 0.008254432119429111], [0.4849108159542084, 0.27474498748779297, 0.13562799990177155, 0.09433116763830185, 0.0103849982842803], [0.21599265933036804, 0.6570193767547607, 0.102354034781456, 0.016337115317583084, 0.008296730928122997], [0.256359338760376, 0.5032808184623718, 0.20782509446144104, 0.026938287541270256, 0.005596511531621218], [0.06341913342475891, 0.6762697696685791, 0.22613580524921417, 0.02704078145325184, 0.007134526036679745], [0.6786518096923828, 0.09245798736810684, 0.14891277253627777, 0.07434342801570892, 0.00563410809263587], [0.06908653676509857, 0.7649317979812622, 0.1520070731639862, 0.009270577691495419, 0.004703930579125881], [0.44855624437332153, 0.10486456751823425, 0.20962034165859222, 0.2222796082496643, 0.014679206535220146], [0.09837668389081955, 0.7196798324584961, 0.15709443390369415, 0.018006499856710434, 0.006842662114650011], [0.49096059799194336, 0.08233676105737686, 0.34119969606399536, 0.07915286719799042, 0.006350024603307247], [0.1280737817287445, 0.014391657896339893, 0.045480914413928986, 0.7944759726524353, 0.017577655613422394], [0.08308357000350952, 0.8168901205062866, 0.0838533341884613, 0.00964285247027874, 0.006530142854899168], [0.15274865925312042, 0.7045422792434692, 0.1264936476945877, 0.011878026649355888, 0.004337484482675791], [0.661661684513092, 0.06116010621190071, 0.04334862530231476, 0.21917952597141266, 0.014650064520537853], [0.06413722783327103, 0.8405497074127197, 0.07312305271625519, 0.01435020286589861, 0.007839725352823734], [0.7206271290779114, 0.038626667112112045, 0.0338253416121006, 0.1952289193868637, 0.011691907420754433], [0.6120229363441467, 0.20561301708221436, 0.12288430333137512, 0.05261985585093498, 0.006859902758151293], [0.2627653479576111, 0.5416427254676819, 0.11369991302490234, 0.0674753338098526, 0.014416597783565521], [0.7462655305862427, 0.12937061488628387, 0.059191394597291946, 0.05629240721464157, 0.008879968896508217], [0.16297197341918945, 0.08790386468172073, 0.6011497974395752, 0.1390829086303711, 0.00889150332659483], [0.6965128183364868, 0.045347001403570175, 0.043128371238708496, 0.20356741547584534, 0.011444354429841042], [0.5013167858123779, 0.0690949559211731, 0.13008752465248108, 0.2866493761539459, 0.012851428240537643], [0.39842110872268677, 0.2775718569755554, 0.16038291156291962, 0.15440769493579865, 0.00921651627868414], [0.7260384559631348, 0.07336729019880295, 0.033953968435525894, 0.15585286915302277, 0.010787430219352245], [0.19797003269195557, 0.6937664151191711, 0.0906323492527008, 0.00974680483341217, 0.00788436271250248], [0.343269020318985, 0.30873456597328186, 0.1963813304901123, 0.14438216388225555, 0.0072328029200434685], [0.262643039226532, 0.5959545969963074, 0.12411922961473465, 0.011274966411292553, 0.006008109077811241], [0.3462531566619873, 0.4534945487976074, 0.1779516637325287, 0.016736140474677086, 0.00556449219584465], [0.3702973425388336, 0.02220386452972889, 0.06480816751718521, 0.5302222371101379, 0.01246849074959755], [0.08640080690383911, 0.7203426361083984, 0.16887065768241882, 0.01276885811239481, 0.011617057025432587], [0.08367658406496048, 0.7569243311882019, 0.14740191400051117, 0.007408285979181528, 0.004588872194290161], [0.592224657535553, 0.1743677854537964, 0.0982438176870346, 0.1294579952955246, 0.005705681629478931], [0.13609492778778076, 0.6380366086959839, 0.13641010224819183, 0.07464687526226044, 0.014811469241976738], [0.05597618594765663, 0.7210577130317688, 0.20333532989025116, 0.012547370977699757, 0.007083476521074772], [0.3786306083202362, 0.47818922996520996, 0.1113915741443634, 0.026219936087727547, 0.0055686961859464645], [0.18399283289909363, 0.5587738752365112, 0.22436079382896423, 0.026411788538098335, 0.006460690870881081], [0.5718845129013062, 0.23420201241970062, 0.1663115918636322, 0.019335495308041573, 0.008266381919384003], [0.07706594467163086, 0.701804518699646, 0.1992257982492447, 0.01587858609855175, 0.006025288719683886], [0.620050847530365, 0.13631926476955414, 0.1763821244239807, 0.059695255011320114, 0.007552504539489746], [0.046010859310626984, 0.42926645278930664, 0.5080127120018005, 0.011452624574303627, 0.005257267039269209], [0.14712898433208466, 0.012668665498495102, 0.07546953856945038, 0.7477198243141174, 0.01701292395591736], [0.5176904797554016, 0.25065892934799194, 0.18484140932559967, 0.04006126523017883, 0.006747955922037363], [0.10910312086343765, 0.8186644911766052, 0.05867746099829674, 0.007364400662481785, 0.0061904448084533215], [0.17158320546150208, 0.02078736014664173, 0.07350814342498779, 0.7207550406455994, 0.013366276398301125], [0.2383730560541153, 0.31459560990333557, 0.4098389446735382, 0.03281166031956673, 0.00438071321696043], [0.4667312800884247, 0.1345883309841156, 0.08534041792154312, 0.3021447956562042, 0.01119519304484129], [0.3815819323062897, 0.29880979657173157, 0.27607205510139465, 0.035618431866168976, 0.007917728275060654], [0.047728002071380615, 0.8062825798988342, 0.13319067656993866, 0.008222555741667747, 0.004576205741614103], [0.3404485285282135, 0.07976098358631134, 0.10992307960987091, 0.4594152867794037, 0.010452080518007278], [0.32223430275917053, 0.05926283821463585, 0.18632212281227112, 0.41181397438049316, 0.020366709679365158], [0.07595311850309372, 0.740061342716217, 0.17382730543613434, 0.004807275719940662, 0.005350885447114706], [0.11071601510047913, 0.7497263550758362, 0.12194152921438217, 0.011620291508734226, 0.005995745770633221], [0.31841063499450684, 0.20653589069843292, 0.3032967448234558, 0.15857675671577454, 0.01317994948476553], [0.04140215367078781, 0.872206449508667, 0.07618722319602966, 0.005018189083784819, 0.005185998044908047], [0.2831462621688843, 0.30949667096138, 0.2768525183200836, 0.12314683198928833, 0.007357727270573378], [0.07763690501451492, 0.7685779333114624, 0.13752080500125885, 0.01056866254657507, 0.0056957462802529335], [0.7630597949028015, 0.05385969206690788, 0.0516979955136776, 0.12297984212636948, 0.008402695879340172], [0.04970396310091019, 0.36925047636032104, 0.5676802396774292, 0.007608508691191673, 0.005756780970841646], [0.3327960669994354, 0.33593469858169556, 0.2875421941280365, 0.03697426617145538, 0.006752734072506428], [0.434167742729187, 0.09908760339021683, 0.37961745262145996, 0.07738884538412094, 0.0097382552921772], [0.22823269665241241, 0.019896795973181725, 0.08143623173236847, 0.6525136232376099, 0.017920635640621185], [0.04975898563861847, 0.8342739343643188, 0.10069667547941208, 0.009194301441311836, 0.006076033227145672], [0.5894075632095337, 0.03734852001070976, 0.05458209663629532, 0.3112896680831909, 0.0073720854707062244], [0.40488627552986145, 0.047219567000865936, 0.09646978229284286, 0.43812254071235657, 0.013301792554557323], [0.46321919560432434, 0.2684774100780487, 0.1515084207057953, 0.10838767886161804, 0.008407204411923885], [0.14414258301258087, 0.7019612193107605, 0.08457529544830322, 0.06281160563230515, 0.006509320344775915], [0.026089387014508247, 0.8526129126548767, 0.10708709806203842, 0.0073049794882535934, 0.006905626971274614], [0.2516174614429474, 0.2435006946325302, 0.2798352837562561, 0.21601611375808716, 0.00903044268488884], [0.47553253173828125, 0.27775320410728455, 0.16931015253067017, 0.06707164645195007, 0.010332537814974785], [0.46145668625831604, 0.11156316101551056, 0.2095150649547577, 0.2097623497247696, 0.00770278787240386], [0.03220463916659355, 0.7495458722114563, 0.18718887865543365, 0.021907351911067963, 0.009153233841061592], [0.08041249960660934, 0.6035202741622925, 0.2992676794528961, 0.011952653527259827, 0.004846899304538965], [0.052024517208337784, 0.8376069664955139, 0.08794105798006058, 0.014450069516897202, 0.007977362722158432], [0.6084602475166321, 0.06868396699428558, 0.0534757636487484, 0.2596493363380432, 0.009730703197419643], [0.4628584682941437, 0.14627107977867126, 0.08178205788135529, 0.2924990952014923, 0.01658926159143448], [0.41221311688423157, 0.32785913348197937, 0.17085117101669312, 0.08367232978343964, 0.005404296331107616], [0.09881441295146942, 0.748688280582428, 0.1322704702615738, 0.0153115876019001, 0.004915306810289621], [0.03746751323342323, 0.7079333662986755, 0.24368850886821747, 0.004453873261809349, 0.006456785369664431], [0.39547428488731384, 0.0929575115442276, 0.08644317835569382, 0.4101084768772125, 0.015016541816294193], [0.0999789834022522, 0.2375500351190567, 0.6077641844749451, 0.044889673590660095, 0.009817107580602169], [0.5538678765296936, 0.29166415333747864, 0.09935751557350159, 0.04728998616337776, 0.007820471189916134], [0.619739294052124, 0.2021196186542511, 0.14751121401786804, 0.0254339762032032, 0.005195809528231621], [0.5820499062538147, 0.23453055322170258, 0.1318691223859787, 0.042856745421886444, 0.00869370810687542], [0.37201061844825745, 0.5247504115104675, 0.07649025321006775, 0.019115997478365898, 0.007632656022906303], [0.06566300988197327, 0.7009413242340088, 0.22103846073150635, 0.00798086728900671, 0.004376293625682592], [0.10909733176231384, 0.5228497385978699, 0.3459748327732086, 0.016277899965643883, 0.005800160113722086], [0.7186346054077148, 0.053417760878801346, 0.046233922243118286, 0.16495241224765778, 0.016761349514126778], [0.3364233374595642, 0.031848032027482986, 0.06494157761335373, 0.5512003898620605, 0.015586643479764462], [0.7144158482551575, 0.17847047746181488, 0.07742925733327866, 0.02469583787024021, 0.0049886154010891914], [0.5407553315162659, 0.16360528767108917, 0.22010724246501923, 0.06971106678247452, 0.005821026396006346], [0.06644802540540695, 0.6693533062934875, 0.2543659508228302, 0.005797243677079678, 0.004035456106066704], [0.3593301773071289, 0.3619627058506012, 0.16707444190979004, 0.09167833626270294, 0.019954437389969826], [0.5250258445739746, 0.19553057849407196, 0.1632033735513687, 0.10707712918519974, 0.009163093753159046], [0.5251668095588684, 0.03347279131412506, 0.045909881591796875, 0.3809761703014374, 0.014474321156740189], [0.18203982710838318, 0.4209750294685364, 0.3133184015750885, 0.07678800821304321, 0.006878598127514124], [0.1621142029762268, 0.19015410542488098, 0.2899514138698578, 0.3414095640182495, 0.016370650380849838], [0.11878150701522827, 0.5833602547645569, 0.2279704213142395, 0.06096615642309189, 0.008921581320464611], [0.4880916178226471, 0.04585148021578789, 0.06434616446495056, 0.39081427454948425, 0.010896528139710426], [0.20072267949581146, 0.275328665971756, 0.2803386449813843, 0.22779802978038788, 0.01581195555627346], [0.04714912548661232, 0.8707120418548584, 0.07119585573673248, 0.005318684037774801, 0.005624227225780487], [0.05244716629385948, 0.6687243580818176, 0.2640918493270874, 0.010613585822284222, 0.0041230847127735615], [0.4807593822479248, 0.317546546459198, 0.10201362520456314, 0.08905152231454849, 0.010628990828990936], [0.04660613834857941, 0.8785951137542725, 0.062684066593647, 0.006372219417244196, 0.005742503795772791], [0.17965716123580933, 0.027448346838355064, 0.13333874940872192, 0.6438943147659302, 0.01566142588853836], [0.08717532455921173, 0.6514021754264832, 0.2452612668275833, 0.010569141246378422, 0.00559214735403657], [0.08161504566669464, 0.5397738218307495, 0.29962876439094543, 0.07028352469205856, 0.008698808960616589], [0.05598929151892662, 0.740271270275116, 0.18912160396575928, 0.008779983036220074, 0.005837815813720226], [0.5301124453544617, 0.0528297945857048, 0.0583348385989666, 0.33527642488479614, 0.023446494713425636], [0.3366793394088745, 0.3070336580276489, 0.2603420615196228, 0.08655887097120285, 0.009386138990521431], [0.3460429906845093, 0.3070463538169861, 0.2775433659553528, 0.0614703968167305, 0.007896896451711655], [0.17535704374313354, 0.456254780292511, 0.33771902322769165, 0.025785868987441063, 0.004883351735770702], [0.36320117115974426, 0.12679395079612732, 0.45309221744537354, 0.051420509815216064, 0.005492262076586485], [0.3006831705570221, 0.054018378257751465, 0.17141644656658173, 0.4591389000415802, 0.014743193984031677], [0.6635850071907043, 0.04243362694978714, 0.10675209015607834, 0.18011966347694397, 0.007109613157808781], [0.05103292316198349, 0.5997570157051086, 0.33939385414123535, 0.0053149638697505, 0.004501247778534889], [0.14422433078289032, 0.4861504137516022, 0.2781936526298523, 0.08134213835000992, 0.010089442133903503], [0.3452477753162384, 0.35052362084388733, 0.13950486481189728, 0.15719600021839142, 0.007527702488005161], [0.7681244015693665, 0.09923982620239258, 0.04559268429875374, 0.07823622226715088, 0.008806849829852581], [0.6459726691246033, 0.12679214775562286, 0.0728546679019928, 0.13682764768600464, 0.017552915960550308], [0.5449308156967163, 0.05116821825504303, 0.029931049793958664, 0.3542381525039673, 0.019731765612959862], [0.21702951192855835, 0.07230671495199203, 0.1182011291384697, 0.5646145939826965, 0.027848051860928535], [0.04141099005937576, 0.6983093619346619, 0.2506871521472931, 0.005127434618771076, 0.004465130157768726], [0.37125176191329956, 0.2818615138530731, 0.24307779967784882, 0.09389219433069229, 0.009916657581925392], [0.06190276890993118, 0.8492863178253174, 0.06273254752159119, 0.016104528680443764, 0.009973791427910328], [0.03433990851044655, 0.5300048589706421, 0.4188360571861267, 0.012131335213780403, 0.004687895532697439], [0.5899549126625061, 0.22449205815792084, 0.10000517964363098, 0.07751032710075378, 0.008037549443542957], [0.15778759121894836, 0.08960619568824768, 0.18016131222248077, 0.5579617619514465, 0.014483144506812096], [0.12030698359012604, 0.7845943570137024, 0.0603940524160862, 0.026308465749025345, 0.008396133780479431], [0.37605389952659607, 0.3772701025009155, 0.21832476556301117, 0.022273927927017212, 0.006077271420508623]]\n",
      "0.836869153752923\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.52      0.53        64\n",
      "           1       0.56      0.78      0.65        63\n",
      "           2       0.48      0.29      0.36        41\n",
      "           3       0.44      0.43      0.44        28\n",
      "           4       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.53       200\n",
      "   macro avg       0.41      0.40      0.40       200\n",
      "weighted avg       0.51      0.53      0.51       200\n",
      "\n",
      "[[0.01654726080596447, 0.41348227858543396, 0.5601692795753479, 0.00470722047612071, 0.005094018764793873], [0.13623708486557007, 0.7584438920021057, 0.08728315681219101, 0.01383760292083025, 0.004198218695819378], [0.2821735441684723, 0.009738771244883537, 0.018934432417154312, 0.6666969060897827, 0.022456327453255653], [0.7468637228012085, 0.08736895769834518, 0.10726906359195709, 0.050435010343790054, 0.008063247427344322], [0.03543255478143692, 0.6761487126350403, 0.2722763121128082, 0.010294453240931034, 0.005847891326993704], [0.19521039724349976, 0.36252886056900024, 0.41169896721839905, 0.024476535618305206, 0.0060852644965052605], [0.09031015634536743, 0.6091464161872864, 0.29038143157958984, 0.005803127307444811, 0.004358839709311724], [0.27282869815826416, 0.12585844099521637, 0.26451703906059265, 0.32359078526496887, 0.01320511195808649], [0.08606579899787903, 0.23914889991283417, 0.6605700254440308, 0.008303447626531124, 0.005911797750741243], [0.6401424407958984, 0.12793980538845062, 0.1679403930902481, 0.05774976313114166, 0.006227589212357998], [0.15890836715698242, 0.5667806267738342, 0.26325589418411255, 0.005675824824720621, 0.005379215814173222], [0.5665169358253479, 0.32383906841278076, 0.047332871705293655, 0.04759626090526581, 0.01471495907753706], [0.20355549454689026, 0.012734048999845982, 0.10412642359733582, 0.6686695218086243, 0.010914496146142483], [0.6383025050163269, 0.12412478029727936, 0.06767291575670242, 0.15639139711856842, 0.013508418574929237], [0.5115599632263184, 0.1322822868824005, 0.13844560086727142, 0.20805688202381134, 0.009655339643359184], [0.41425782442092896, 0.01321617141366005, 0.03780872002243996, 0.5229809880256653, 0.011736375279724598], [0.2954670786857605, 0.3400755822658539, 0.1537627875804901, 0.18812260031700134, 0.022571967914700508], [0.42911940813064575, 0.017317544668912888, 0.03493421897292137, 0.5078258514404297, 0.01080293394625187], [0.07037078589200974, 0.3461664021015167, 0.5704213380813599, 0.009691530838608742, 0.003349905600771308], [0.7365248203277588, 0.042457662522792816, 0.1200348436832428, 0.09595063328742981, 0.005032090935856104], [0.47533851861953735, 0.3166637122631073, 0.04569580405950546, 0.1490636020898819, 0.013238325715065002], [0.14734576642513275, 0.6457306742668152, 0.19011613726615906, 0.012881106697022915, 0.003926316741853952], [0.30643656849861145, 0.017820779234170914, 0.02950645610690117, 0.6321882009506226, 0.014047935605049133], [0.08256922662258148, 0.5253005027770996, 0.37812164425849915, 0.00874332245439291, 0.005265270359814167], [0.5413071513175964, 0.19630472362041473, 0.07979695498943329, 0.15850241482257843, 0.024088766425848007], [0.0216829851269722, 0.93470299243927, 0.0366351343691349, 0.0021316143684089184, 0.0048472145572304726], [0.11525700241327286, 0.8036708831787109, 0.07191313803195953, 0.004418847616761923, 0.004740188829600811], [0.34350505471229553, 0.5041020512580872, 0.12261483073234558, 0.02278708480298519, 0.006990975234657526], [0.14583557844161987, 0.5527636408805847, 0.28659242391586304, 0.008510338142514229, 0.006298020016402006], [0.45871463418006897, 0.04500845447182655, 0.03755658119916916, 0.4340049922466278, 0.02471533790230751], [0.6129350662231445, 0.21939091384410858, 0.12216871231794357, 0.04037308320403099, 0.005132171791046858], [0.6237903833389282, 0.1638578474521637, 0.16962356865406036, 0.03788342326879501, 0.00484468974173069], [0.02064240537583828, 0.8778510689735413, 0.09342113882303238, 0.0029661892913281918, 0.005119129084050655], [0.0878753811120987, 0.3347421884536743, 0.5533024072647095, 0.018595591187477112, 0.005484408233314753], [0.018219320103526115, 0.7986637949943542, 0.17552080750465393, 0.0041615222580730915, 0.00343458098359406], [0.30521300435066223, 0.03124053403735161, 0.18297287821769714, 0.4700016379356384, 0.010571908205747604], [0.017732437700033188, 0.8700844645500183, 0.10507166385650635, 0.0032532995101064444, 0.0038580831605941057], [0.40514153242111206, 0.47813621163368225, 0.08012988418340683, 0.03105679713189602, 0.005535701755434275], [0.6787747740745544, 0.10437760502099991, 0.04805862903594971, 0.15551918745040894, 0.013269870541989803], [0.017120003700256348, 0.7227128744125366, 0.25214406847953796, 0.00384682253934443, 0.004176272079348564], [0.792500376701355, 0.030499504879117012, 0.018853280693292618, 0.1449538618326187, 0.013192898593842983], [0.5903570055961609, 0.11093829572200775, 0.20444121956825256, 0.08435020595788956, 0.009913223795592785], [0.26315248012542725, 0.4151833951473236, 0.29852980375289917, 0.01849016733467579, 0.0046442183665931225], [0.38243359327316284, 0.12123971432447433, 0.3642534911632538, 0.12361115962266922, 0.00846211425960064], [0.022119775414466858, 0.8769574165344238, 0.08571450412273407, 0.0078070093877613544, 0.007401268929243088], [0.03826186805963516, 0.8404968976974487, 0.10468785464763641, 0.011444030329585075, 0.005109294317662716], [0.028050141409039497, 0.6580526828765869, 0.3055665194988251, 0.004327352158725262, 0.004003303125500679], [0.041059140115976334, 0.9034674167633057, 0.04468780755996704, 0.0051000383682549, 0.005685717798769474], [0.03404821455478668, 0.5723703503608704, 0.3748597800731659, 0.01405805628746748, 0.004663511179387569], [0.15652728080749512, 0.39847585558891296, 0.41702383756637573, 0.022666554898023605, 0.005306420847773552], [0.06823815405368805, 0.8998541831970215, 0.023676468059420586, 0.003039295319467783, 0.005191908683627844], [0.15516406297683716, 0.4698539078235626, 0.36175301671028137, 0.008537271060049534, 0.004691645503044128], [0.01624588668346405, 0.9203031063079834, 0.05401109531521797, 0.00424914387986064, 0.0051907445304095745], [0.04737725108861923, 0.6417627334594727, 0.2975890636444092, 0.00726393423974514, 0.0060070110484957695], [0.1165902316570282, 0.06854910403490067, 0.7509975433349609, 0.05606149882078171, 0.00780165009200573], [0.022672798484563828, 0.8339325785636902, 0.1359769105911255, 0.0036620807368308306, 0.00375558203086257], [0.12197723239660263, 0.23138847947120667, 0.611724853515625, 0.028333384543657303, 0.00657606590539217], [0.6613880395889282, 0.03353789448738098, 0.05167379975318909, 0.24604101479053497, 0.00735935615375638], [0.013473969884216785, 0.9074613451957703, 0.06558825820684433, 0.007201394997537136, 0.006275058723986149], [0.401127427816391, 0.2722296416759491, 0.27584758400917053, 0.041627440601587296, 0.009167865850031376], [0.06572834402322769, 0.5854231715202332, 0.31871262192726135, 0.02371273562312126, 0.006423134356737137], [0.46366411447525024, 0.01753285527229309, 0.04035167023539543, 0.46705886721611023, 0.011392396874725819], [0.050266530364751816, 0.006096735130995512, 0.0652618259191513, 0.8649430871009827, 0.013431865721940994], [0.12190324813127518, 0.7196184992790222, 0.13671810925006866, 0.014600408263504505, 0.007159760221838951], [0.3231625556945801, 0.06911604851484299, 0.41950729489326477, 0.17614828050136566, 0.012065824121236801], [0.607059121131897, 0.18600547313690186, 0.14924095571041107, 0.04807008430361748, 0.009624297730624676], [0.14327208697795868, 0.5126668214797974, 0.3294700086116791, 0.008269963786005974, 0.006321075838059187], [0.238932803273201, 0.08428442478179932, 0.35446205735206604, 0.3061888515949249, 0.016131959855556488], [0.17770707607269287, 0.5858713388442993, 0.21816328167915344, 0.012953243218362331, 0.005305036902427673], [0.205396369099617, 0.3299753963947296, 0.356491357088089, 0.09769205749034882, 0.010444874875247478], [0.09656503051519394, 0.8684490323066711, 0.025227608159184456, 0.004593067802488804, 0.005165316630154848], [0.29385024309158325, 0.606306254863739, 0.06611180305480957, 0.02625446207821369, 0.007477199658751488], [0.3821423649787903, 0.3900879919528961, 0.14851443469524384, 0.06818662583827972, 0.011068583466112614], [0.2127377688884735, 0.6945463418960571, 0.07219956070184708, 0.01112062856554985, 0.00939574558287859], [0.27414900064468384, 0.5311945676803589, 0.1640218049287796, 0.023274678736925125, 0.007360017392784357], [0.0329553596675396, 0.7362880110740662, 0.20975397527217865, 0.014894639141857624, 0.006108024623245001], [0.6283433437347412, 0.08796518296003342, 0.23192034661769867, 0.04544011875987053, 0.006331011652946472], [0.03368604928255081, 0.8197483420372009, 0.13775277137756348, 0.0048040421679615974, 0.0040088738314807415], [0.33274221420288086, 0.0623512789607048, 0.21981745958328247, 0.3690122365951538, 0.016076792031526566], [0.08643606305122375, 0.733931303024292, 0.16001594066619873, 0.01301608607172966, 0.006600494962185621], [0.42590439319610596, 0.043382253497838974, 0.41235992312431335, 0.11000959575176239, 0.008343838155269623], [0.06015621870756149, 0.0070504541508853436, 0.027303272858262062, 0.8881021738052368, 0.017387913540005684], [0.05030464008450508, 0.8914774060249329, 0.04871030151844025, 0.0041902256198227406, 0.00531747005879879], [0.16516384482383728, 0.7051503658294678, 0.11583194136619568, 0.008815165609121323, 0.005038569215685129], [0.6079402565956116, 0.027940718457102776, 0.03015027940273285, 0.31650233268737793, 0.017466338351368904], [0.041054897010326385, 0.9027870893478394, 0.0436776801943779, 0.0067780837416648865, 0.005702232010662556], [0.7946472764015198, 0.025426333770155907, 0.02187288925051689, 0.1484161913394928, 0.009637397713959217], [0.5836799740791321, 0.27327844500541687, 0.10126540809869766, 0.03355436399579048, 0.008221768774092197], [0.35427603125572205, 0.4763655662536621, 0.09279543906450272, 0.06262649595737457, 0.013936488889157772], [0.78773033618927, 0.13428527116775513, 0.046790625900030136, 0.024176403880119324, 0.007017398718744516], [0.05733637884259224, 0.03430866450071335, 0.8001367449760437, 0.10001131892204285, 0.008206846192479134], [0.8364372253417969, 0.037607014179229736, 0.03442195802927017, 0.08275678008794785, 0.008776973932981491], [0.4488889276981354, 0.05594492703676224, 0.1806412935256958, 0.3006912171840668, 0.013833735138177872], [0.4964318573474884, 0.23423674702644348, 0.10708805918693542, 0.15165875852108002, 0.010584592819213867], [0.8159181475639343, 0.0485534705221653, 0.018897419795393944, 0.10785948485136032, 0.00877148937433958], [0.1668481081724167, 0.7752647995948792, 0.04485616460442543, 0.005253358278423548, 0.007777536753565073], [0.19304849207401276, 0.39426809549331665, 0.307847261428833, 0.09691186994314194, 0.007924227975308895], [0.18729786574840546, 0.7020832300186157, 0.10053025931119919, 0.005252531263977289, 0.0048361229710280895], [0.7147163152694702, 0.17217129468917847, 0.09075452387332916, 0.01639229990541935, 0.005965584423393011], [0.26730963587760925, 0.01227313932031393, 0.04488307610154152, 0.6621417999267578, 0.01339228730648756], [0.07896813750267029, 0.6219278573989868, 0.27943533658981323, 0.009419523179531097, 0.010249105282127857], [0.0695897564291954, 0.8047609925270081, 0.11767823994159698, 0.004126281943172216, 0.003844731254503131], [0.7210909724235535, 0.13365507125854492, 0.05895319953560829, 0.08130796253681183, 0.004992900416254997], [0.14823657274246216, 0.6097739934921265, 0.1520737111568451, 0.07454978674650192, 0.01536592748016119], [0.03285185620188713, 0.763271689414978, 0.18934349715709686, 0.007896249182522297, 0.0066366856917738914], [0.46331140398979187, 0.398439884185791, 0.11679551005363464, 0.015138380229473114, 0.00631483132019639], [0.21288393437862396, 0.4919911324977875, 0.2569506764411926, 0.030155811458826065, 0.008018512278795242], [0.6627369523048401, 0.20135657489299774, 0.11622373759746552, 0.01095852442085743, 0.008724166080355644], [0.06331575661897659, 0.6813547611236572, 0.23372676968574524, 0.015217063017189503, 0.006385742221027613], [0.6796883940696716, 0.09932535141706467, 0.17616510391235352, 0.03847133740782738, 0.00634983042255044], [0.02471928671002388, 0.3441018760204315, 0.617822527885437, 0.008264883421361446, 0.005091463215649128], [0.048669442534446716, 0.0043273987248539925, 0.03312903642654419, 0.8985822796821594, 0.015291872434318066], [0.4033687114715576, 0.3564644455909729, 0.2188582420349121, 0.01589321345090866, 0.005415331572294235], [0.06581862270832062, 0.888131320476532, 0.03739457577466965, 0.003452219534665346, 0.005203363485634327], [0.07528126239776611, 0.007688288576900959, 0.028920046985149384, 0.874819815158844, 0.0132906474173069], [0.23353952169418335, 0.1895933300256729, 0.534295916557312, 0.03793106973171234, 0.004640144295990467], [0.4561980068683624, 0.1948230117559433, 0.0996980294585228, 0.23297610878944397, 0.016304921358823776], [0.2903743088245392, 0.29755884408950806, 0.3879196047782898, 0.017296278849244118, 0.006850930396467447], [0.024491533637046814, 0.8673921823501587, 0.09983215481042862, 0.004335238132625818, 0.003948981408029795], [0.3258425295352936, 0.02876596711575985, 0.050030406564474106, 0.5821669697761536, 0.01319414097815752], [0.2729092836380005, 0.044613536447286606, 0.1907881647348404, 0.47111859917640686, 0.020570313557982445], [0.04182638227939606, 0.8223579525947571, 0.12903712689876556, 0.0023627032060176134, 0.004415871109813452], [0.06642724573612213, 0.8610896468162537, 0.0622912235558033, 0.0051399278454482555, 0.005051976069808006], [0.3102109432220459, 0.10864123702049255, 0.25489377975463867, 0.2977580428123474, 0.02849602699279785], [0.023694414645433426, 0.9354462623596191, 0.03346742317080498, 0.0026280649472028017, 0.0047638146206736565], [0.21395108103752136, 0.3533143401145935, 0.3259339928627014, 0.09968298673629761, 0.007117588073015213], [0.04911751300096512, 0.8421531915664673, 0.09925317019224167, 0.004671294242143631, 0.004804893862456083], [0.6123554110527039, 0.019175194203853607, 0.041547175496816635, 0.3128097355365753, 0.014112552627921104], [0.03595408424735069, 0.1976463794708252, 0.755355954170227, 0.005910796113312244, 0.005132791120558977], [0.40288829803466797, 0.26237422227859497, 0.30053383111953735, 0.025694232434034348, 0.008509441278874874], [0.45410317182540894, 0.03727525472640991, 0.3765828013420105, 0.1194363534450531, 0.012602484785020351], [0.09325621277093887, 0.007834029383957386, 0.042072657495737076, 0.8382745981216431, 0.01856251247227192], [0.030529692769050598, 0.8962241411209106, 0.06365404278039932, 0.004704033490270376, 0.004888212773948908], [0.4711969494819641, 0.015726439654827118, 0.02983717806637287, 0.4737931489944458, 0.009446312673389912], [0.2073172777891159, 0.019200393930077553, 0.06487380713224411, 0.6922027468681335, 0.0164057444781065], [0.5755670070648193, 0.13652606308460236, 0.10821153968572617, 0.17076872289180756, 0.008926589041948318], [0.04368266463279724, 0.8973283171653748, 0.042843159288167953, 0.012004304677248001, 0.004141620825976133], [0.014591503888368607, 0.9006272554397583, 0.07436133176088333, 0.004388783127069473, 0.0060311309061944485], [0.16751255095005035, 0.18091487884521484, 0.4939004182815552, 0.1485617607831955, 0.009110459126532078], [0.3151912987232208, 0.47798776626586914, 0.17440055310726166, 0.02422361448407173, 0.008196714334189892], [0.368383526802063, 0.027197763323783875, 0.09403164684772491, 0.49804162979125977, 0.012345436029136181], [0.01972190849483013, 0.7717038989067078, 0.18363437056541443, 0.016818149015307426, 0.008121669292449951], [0.052791744470596313, 0.5115490555763245, 0.42162367701530457, 0.009482561610639095, 0.004552971106022596], [0.025662707164883614, 0.8902032971382141, 0.0705874040722847, 0.006762905512005091, 0.006783650256693363], [0.5716202259063721, 0.04104930907487869, 0.03479025885462761, 0.33953607082366943, 0.013004172593355179], [0.43827176094055176, 0.11410973221063614, 0.07840932905673981, 0.3497379720211029, 0.01947113312780857], [0.5000166296958923, 0.2903159558773041, 0.13313688337802887, 0.0712997242808342, 0.00523075507953763], [0.07413113862276077, 0.8394226431846619, 0.07307746261358261, 0.008843033574521542, 0.00452578067779541], [0.023230774328112602, 0.7349173426628113, 0.23458746075630188, 0.002508235163986683, 0.0047562140971422195], [0.43475621938705444, 0.06418213248252869, 0.0629381537437439, 0.4230949580669403, 0.015028583817183971], [0.06675433367490768, 0.19335350394248962, 0.6961153745651245, 0.03392792493104935, 0.009848818182945251], [0.3353462219238281, 0.5730457901954651, 0.07078899443149567, 0.013295752927660942, 0.007523153908550739], [0.7231881618499756, 0.14755576848983765, 0.11185025423765182, 0.013513246551156044, 0.0038925812114030123], [0.656831681728363, 0.21596486866474152, 0.10257413238286972, 0.017262080684304237, 0.007367321290075779], [0.3920401334762573, 0.5461922883987427, 0.04694882035255432, 0.008429262787103653, 0.006389496382325888], [0.03057800605893135, 0.8063745498657227, 0.15482187271118164, 0.004313341341912746, 0.0039122807793319225], [0.10343974083662033, 0.3747575879096985, 0.49205756187438965, 0.02131609618663788, 0.008429033681750298], [0.8705333471298218, 0.04314778000116348, 0.028369000181555748, 0.05062856152653694, 0.00732137868180871], [0.21839426457881927, 0.013613095507025719, 0.050677355378866196, 0.7032305598258972, 0.014084727503359318], [0.703236997127533, 0.2091819941997528, 0.06816703081130981, 0.014093990437686443, 0.005319967400282621], [0.7297185659408569, 0.05301452800631523, 0.12716440856456757, 0.08385922759771347, 0.006243232637643814], [0.0356748066842556, 0.769173264503479, 0.18847744166851044, 0.0031077673193067312, 0.003566713770851493], [0.35262373089790344, 0.42314791679382324, 0.1564643681049347, 0.05085507035255432, 0.016908837482333183], [0.5104502439498901, 0.0524505153298378, 0.1016911193728447, 0.3205271065235138, 0.014881030656397343], [0.3416435122489929, 0.011056816205382347, 0.023254500702023506, 0.6067633032798767, 0.01728186197578907], [0.16282424330711365, 0.3983379006385803, 0.3818858563899994, 0.05034240707755089, 0.006609579082578421], [0.1356811374425888, 0.12226881086826324, 0.3619772791862488, 0.36291825771331787, 0.017154434695839882], [0.11551745980978012, 0.40782904624938965, 0.370144784450531, 0.09343624114990234, 0.013072479516267776], [0.5094079375267029, 0.03023250214755535, 0.06381476670503616, 0.38677331805229187, 0.009771507233381271], [0.2009902149438858, 0.1524520218372345, 0.30112865567207336, 0.3253336250782013, 0.020095424726605415], [0.025484897196292877, 0.9285508394241333, 0.03940486162900925, 0.0023368888068944216, 0.004222401883453131], [0.038152337074279785, 0.6492757201194763, 0.30060452222824097, 0.008170518092811108, 0.0037968887481838465], [0.4400339722633362, 0.38632792234420776, 0.10594425350427628, 0.05718846619129181, 0.01050540804862976], [0.030120117589831352, 0.9311792850494385, 0.03107587993144989, 0.0031304999720305204, 0.004494188353419304], [0.09463745355606079, 0.012324956245720387, 0.07274459302425385, 0.7993826270103455, 0.02091030590236187], [0.0722077488899231, 0.5717741250991821, 0.33990299701690674, 0.009580840356647968, 0.006534322164952755], [0.0655485987663269, 0.47480612993240356, 0.3814442455768585, 0.06893481314182281, 0.009266178123652935], [0.02986893244087696, 0.7728022336959839, 0.1877325028181076, 0.005037109833210707, 0.004559298511594534], [0.46946048736572266, 0.02607835829257965, 0.032434944063425064, 0.44626545906066895, 0.025760794058442116], [0.3081761300563812, 0.2551715672016144, 0.3511335253715515, 0.07626015692949295, 0.009258560836315155], [0.5042173862457275, 0.09515579789876938, 0.2621270716190338, 0.12590381503105164, 0.01259590219706297], [0.13711903989315033, 0.2555962800979614, 0.5786305069923401, 0.023704668506979942, 0.004949458409100771], [0.4161447286605835, 0.09189078956842422, 0.446977436542511, 0.03993598371744156, 0.005051121581345797], [0.1346861869096756, 0.012367808260023594, 0.08042169362306595, 0.7581619024276733, 0.014362487941980362], [0.6262078881263733, 0.04281400144100189, 0.22270986437797546, 0.10283852368593216, 0.005429837852716446], [0.03129942715167999, 0.5951579809188843, 0.3655211925506592, 0.003616431262344122, 0.004404990002512932], [0.06951793283224106, 0.41179075837135315, 0.45964697003364563, 0.049247533082962036, 0.00979684665799141], [0.37675854563713074, 0.2917097210884094, 0.15912675857543945, 0.16576240956783295, 0.0066426657140254974], [0.8513175249099731, 0.06905725598335266, 0.022934280335903168, 0.04908233508467674, 0.007608604151755571], [0.7838572263717651, 0.05529242008924484, 0.03749549016356468, 0.10987742245197296, 0.013477366417646408], [0.6147541999816895, 0.039999257773160934, 0.018582593649625778, 0.3078707754611969, 0.018793145194649696], [0.21891596913337708, 0.0676293596625328, 0.12667827308177948, 0.5537838339805603, 0.032992564141750336], [0.028479769825935364, 0.6318724155426025, 0.33231067657470703, 0.003484725020825863, 0.0038524491246789694], [0.4019474685192108, 0.13794216513633728, 0.30830851197242737, 0.13824370503425598, 0.013558141887187958], [0.04139867052435875, 0.9025722742080688, 0.03927644342184067, 0.008344069123268127, 0.008408485911786556], [0.020945955067873, 0.336380273103714, 0.625777542591095, 0.011467182077467442, 0.0054290564730763435], [0.5022714138031006, 0.36884599924087524, 0.09878449141979218, 0.02410489320755005, 0.005993212573230267], [0.07648719847202301, 0.13719965517520905, 0.4098593294620514, 0.36157137155532837, 0.014882423914968967], [0.09665633738040924, 0.8370654582977295, 0.04028358310461044, 0.019170597195625305, 0.006824036594480276], [0.32416242361068726, 0.49598175287246704, 0.16308876872062683, 0.011114640161395073, 0.005652428139001131]]\n",
      "0.5260258195921779\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.53      0.50        64\n",
      "           1       0.64      0.60      0.62        63\n",
      "           2       0.44      0.39      0.42        41\n",
      "           3       0.41      0.50      0.45        28\n",
      "           4       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.51       200\n",
      "   macro avg       0.40      0.40      0.40       200\n",
      "weighted avg       0.50      0.51      0.51       200\n",
      "\n",
      "[[0.014139531180262566, 0.287685751914978, 0.6888929009437561, 0.004362752661108971, 0.004919108934700489], [0.27752751111984253, 0.5484423041343689, 0.14253991842269897, 0.026161959394812584, 0.005328225903213024], [0.21043163537979126, 0.0068855551071465015, 0.016111986711621284, 0.7472229599952698, 0.019347872585058212], [0.8215557336807251, 0.03913801535964012, 0.0724915936589241, 0.05978919938206673, 0.007025559898465872], [0.030914003029465675, 0.5472410321235657, 0.40478524565696716, 0.010632738471031189, 0.0064269923605024815], [0.2271261215209961, 0.17557550966739655, 0.5635915994644165, 0.02771882712841034, 0.005988057237118483], [0.1330839991569519, 0.43142199516296387, 0.4240066707134247, 0.00700040627270937, 0.004486968740820885], [0.21258856356143951, 0.04785913601517677, 0.2347816675901413, 0.49116069078445435, 0.013610070571303368], [0.08042919635772705, 0.1333286613225937, 0.7728993892669678, 0.007673509418964386, 0.005669193342328072], [0.6948233842849731, 0.05160895735025406, 0.1328725814819336, 0.1139829084277153, 0.006712196860462427], [0.17893654108047485, 0.4396713376045227, 0.3698658049106598, 0.005947506986558437, 0.005578841548413038], [0.7352480292320251, 0.15820030868053436, 0.0355428121984005, 0.05563407391309738, 0.015374729409813881], [0.14630579948425293, 0.007632712367922068, 0.09417334198951721, 0.7405099868774414, 0.011378246359527111], [0.67118901014328, 0.04328545928001404, 0.0456262044608593, 0.22333219647407532, 0.01656719297170639], [0.6054786443710327, 0.06349720060825348, 0.08693711459636688, 0.2345433533191681, 0.00954364612698555], [0.31772541999816895, 0.007874054834246635, 0.02586224488914013, 0.6367470622062683, 0.011791192926466465], [0.31723374128341675, 0.29518139362335205, 0.17872750759124756, 0.18920299410820007, 0.019654393196105957], [0.31486064195632935, 0.008819199167191982, 0.027344388887286186, 0.6376335620880127, 0.011342184618115425], [0.09873775392770767, 0.1968839317560196, 0.6890024542808533, 0.011632044799625874, 0.003743828507140279], [0.7222994565963745, 0.02211654745042324, 0.12000906467437744, 0.13003601133823395, 0.005538943689316511], [0.600935161113739, 0.13793951272964478, 0.04270778223872185, 0.20124977827072144, 0.017167769372463226], [0.2672189474105835, 0.45879605412483215, 0.25016841292381287, 0.019290566444396973, 0.00452601071447134], [0.25924256443977356, 0.010213167406618595, 0.02222195826470852, 0.694142758846283, 0.014179578050971031], [0.09829120337963104, 0.36736607551574707, 0.5186055302619934, 0.010326186195015907, 0.005411053076386452], [0.6230452060699463, 0.14261755347251892, 0.06920620054006577, 0.14393240213394165, 0.021198712289333344], [0.021315427497029305, 0.9349700212478638, 0.03735945373773575, 0.0018598735332489014, 0.004495264030992985], [0.1383577138185501, 0.764014482498169, 0.08831117302179337, 0.004193146713078022, 0.0051234932616353035], [0.49459242820739746, 0.3221663236618042, 0.14937376976013184, 0.026538817211985588, 0.00732865696772933], [0.10472581535577774, 0.5617093443870544, 0.32131853699684143, 0.005789115559309721, 0.006457171402871609], [0.40501365065574646, 0.024052107706665993, 0.02844378910958767, 0.5174596309661865, 0.025030802935361862], [0.7780322432518005, 0.05076923593878746, 0.0825200080871582, 0.0837310254573822, 0.004947586916387081], [0.7682501673698425, 0.0576605387032032, 0.11323262751102448, 0.056149229407310486, 0.004707341082394123], [0.020470336079597473, 0.8276782035827637, 0.14389657974243164, 0.00288217281922698, 0.005072747357189655], [0.12234964966773987, 0.14914053678512573, 0.6944906115531921, 0.027633918449282646, 0.006385228596627712], [0.02052762731909752, 0.6573481559753418, 0.3138361871242523, 0.004882728215306997, 0.0034053046256303787], [0.2674897015094757, 0.0166537556797266, 0.16013741493225098, 0.5437779426574707, 0.011941231787204742], [0.018549731001257896, 0.8264459371566772, 0.14801958203315735, 0.003137469058856368, 0.0038473496679216623], [0.5555756688117981, 0.323196679353714, 0.0835445299744606, 0.032201893627643585, 0.005481264088302851], [0.6804219484329224, 0.046472419053316116, 0.038545649498701096, 0.2190125584602356, 0.015547391027212143], [0.018897349014878273, 0.6039895415306091, 0.3687473237514496, 0.003906814847141504, 0.004459055606275797], [0.7476386427879333, 0.018534384667873383, 0.016608884558081627, 0.19993501901626587, 0.017283111810684204], [0.6468585729598999, 0.06353238970041275, 0.18496763706207275, 0.0951051190495491, 0.009536278434097767], [0.4103772044181824, 0.21530663967132568, 0.3453153967857361, 0.02436838671565056, 0.004632327239960432], [0.4048856496810913, 0.0660947933793068, 0.37079185247421265, 0.1495242714881897, 0.00870346836745739], [0.019803674891591072, 0.857343852519989, 0.10752275586128235, 0.007913446985185146, 0.007416349370032549], [0.03406317159533501, 0.81584632396698, 0.1347123235464096, 0.010264985263347626, 0.005113077815622091], [0.03894782066345215, 0.4622144401073456, 0.48916709423065186, 0.0052829463966190815, 0.0043877349235117435], [0.046438541263341904, 0.8922855854034424, 0.05098722130060196, 0.005024218466132879, 0.00526437908411026], [0.04168669134378433, 0.3797757625579834, 0.5529620051383972, 0.020382074639201164, 0.005193502642214298], [0.2257915437221527, 0.19400469958782196, 0.540833592414856, 0.033413343131542206, 0.005956810899078846], [0.08779957890510559, 0.8815381526947021, 0.022591782733798027, 0.0029851996805518866, 0.005085221491754055], [0.25066572427749634, 0.2520785927772522, 0.48062101006507874, 0.01140617299824953, 0.005228567402809858], [0.013901201076805592, 0.9183683395385742, 0.059090279042720795, 0.0036874902434647083, 0.004952770192176104], [0.04625382646918297, 0.46160998940467834, 0.4786941111087799, 0.007737480103969574, 0.005704585462808609], [0.12745517492294312, 0.032815657556056976, 0.7467246055603027, 0.08409596979618073, 0.008908607065677643], [0.030439626425504684, 0.7531523704528809, 0.20871104300022125, 0.0037479104939848185, 0.003949085716158152], [0.13121727108955383, 0.10418097674846649, 0.7164691090583801, 0.04054224118590355, 0.007590492721647024], [0.5948449373245239, 0.01584453135728836, 0.03320278972387314, 0.34731075167655945, 0.008796928450465202], [0.011829890310764313, 0.8965303897857666, 0.07840412855148315, 0.007305517792701721, 0.0059300679713487625], [0.42963290214538574, 0.17396529018878937, 0.3485865294933319, 0.03922950476408005, 0.008585797622799873], [0.06225552409887314, 0.4782693386077881, 0.43043282628059387, 0.0225460734218359, 0.006496303714811802], [0.2961348593235016, 0.009064127691090107, 0.026644064113497734, 0.6542074680328369, 0.013949478976428509], [0.03642870858311653, 0.003842544974759221, 0.056536950170993805, 0.8894356489181519, 0.013756188564002514], [0.20845302939414978, 0.5329405069351196, 0.22298182547092438, 0.02595127373933792, 0.009673349559307098], [0.34844276309013367, 0.030172962695360184, 0.28762784600257874, 0.31929951906204224, 0.014456999488174915], [0.7275067567825317, 0.060437701642513275, 0.09578859061002731, 0.10463380813598633, 0.011633320711553097], [0.12179397791624069, 0.4492754638195038, 0.41641852259635925, 0.006653882563114166, 0.005858175922185183], [0.22222235798835754, 0.046773768961429596, 0.37496551871299744, 0.3392161726951599, 0.016822153702378273], [0.3760087192058563, 0.275360643863678, 0.30853527784347534, 0.03272781893610954, 0.007367617450654507], [0.24309290945529938, 0.16832107305526733, 0.4323779046535492, 0.14374209940433502, 0.012465987354516983], [0.13879024982452393, 0.8243127465248108, 0.025952043011784554, 0.00516794016584754, 0.005777054000645876], [0.51578688621521, 0.3693966269493103, 0.06959446519613266, 0.03690168634057045, 0.008320274762809277], [0.5113320350646973, 0.22445230185985565, 0.15823347866535187, 0.09390106052160263, 0.012081089429557323], [0.3977760374546051, 0.4864899218082428, 0.0882878378033638, 0.0159370768815279, 0.011509018018841743], [0.29943010210990906, 0.47406867146492004, 0.20183593034744263, 0.017797181382775307, 0.00686804810538888], [0.03300949186086655, 0.6294118762016296, 0.315149188041687, 0.016248108819127083, 0.0061812796629965305], [0.707495391368866, 0.03771248832345009, 0.19221511483192444, 0.05592963472008705, 0.006647355854511261], [0.04477206617593765, 0.7323887944221497, 0.21272143721580505, 0.005619397386908531, 0.004498268477618694], [0.2954595983028412, 0.03139893710613251, 0.19120749831199646, 0.46521633863449097, 0.016717620193958282], [0.10543456673622131, 0.6648203730583191, 0.20711307227611542, 0.015359606593847275, 0.0072723799385130405], [0.4400003254413605, 0.020763948559761047, 0.37254562973976135, 0.15715554356575012, 0.009534508921205997], [0.043749623000621796, 0.004382951185107231, 0.023369474336504936, 0.9123536944389343, 0.016144240275025368], [0.06277197599411011, 0.8625668883323669, 0.06432701647281647, 0.0044295149855315685, 0.005904586054384708], [0.32722601294517517, 0.46440598368644714, 0.1885446459054947, 0.013906273059546947, 0.00591705460101366], [0.5138506293296814, 0.01574523374438286, 0.025634586811065674, 0.425007164478302, 0.01976246014237404], [0.04590516909956932, 0.8924897313117981, 0.049262166023254395, 0.0067852758802473545, 0.005557609256356955], [0.7746789455413818, 0.014754397794604301, 0.018271762877702713, 0.18071669340133667, 0.01157811563462019], [0.7114502787590027, 0.14670799672603607, 0.09720959514379501, 0.03734708949923515, 0.007285051979124546], [0.502932071685791, 0.316689670085907, 0.08622565865516663, 0.07833339273929596, 0.015819160267710686], [0.8764278888702393, 0.04564047232270241, 0.031089792028069496, 0.039670009166002274, 0.007171815726906061], [0.05193778872489929, 0.017371797934174538, 0.7851482033729553, 0.13515745103359222, 0.010384767316281796], [0.8232375383377075, 0.022164957597851753, 0.029909096658229828, 0.11443119496107101, 0.010257096961140633], [0.45388489961624146, 0.029671940952539444, 0.16044311225414276, 0.3416495621204376, 0.014350496232509613], [0.6035033464431763, 0.17996639013290405, 0.10355949401855469, 0.10397063195705414, 0.009000195190310478], [0.8077436685562134, 0.024304408580064774, 0.014704725705087185, 0.14307084679603577, 0.010176393203437328], [0.24559295177459717, 0.6952642202377319, 0.043843772262334824, 0.006046136375516653, 0.009252837859094143], [0.17997032403945923, 0.2648911774158478, 0.44674235582351685, 0.09961305558681488, 0.008783087134361267], [0.2628762125968933, 0.6084450483322144, 0.11827044934034348, 0.005538216792047024, 0.004870081320405006], [0.8595689535140991, 0.057315487414598465, 0.05378388240933418, 0.023491470143198967, 0.005840231664478779], [0.23258334398269653, 0.00742348562926054, 0.0397685207426548, 0.7074446082115173, 0.012780038639903069], [0.08625707030296326, 0.4932752251625061, 0.4001762866973877, 0.009709108620882034, 0.01058233343064785], [0.10484308749437332, 0.6923721432685852, 0.1937694102525711, 0.004576824139803648, 0.004438447300344706], [0.7919902801513672, 0.054849423468112946, 0.04271847754716873, 0.10534030199050903, 0.005101615097373724], [0.19625237584114075, 0.508811891078949, 0.18684475123882294, 0.09167197346687317, 0.01641896367073059], [0.029855255037546158, 0.7034331560134888, 0.25183770060539246, 0.008089063689112663, 0.006784801371395588], [0.6106206774711609, 0.24936066567897797, 0.11652599275112152, 0.017120616510510445, 0.0063721127808094025], [0.4046480655670166, 0.2679527997970581, 0.2737673223018646, 0.04445965588092804, 0.009172135032713413], [0.8099926114082336, 0.08740972727537155, 0.08206295967102051, 0.013008116744458675, 0.007526697125285864], [0.08367606997489929, 0.49502813816070557, 0.38957682251930237, 0.0233556367456913, 0.008363388478755951], [0.7629250884056091, 0.03569653630256653, 0.13233883678913116, 0.06284783780574799, 0.006191765423864126], [0.021762549877166748, 0.17781303822994232, 0.7887071967124939, 0.00727358553558588, 0.00444365106523037], [0.03704769164323807, 0.002877717139199376, 0.026650320738554, 0.918999969959259, 0.014424238353967667], [0.48380985856056213, 0.18295712769031525, 0.3067811131477356, 0.02063090167939663, 0.005821035709232092], [0.08100087940692902, 0.8673665523529053, 0.04284738749265671, 0.0034124599769711494, 0.005372822284698486], [0.06077229976654053, 0.005008126143366098, 0.02404315583407879, 0.8986932039260864, 0.011483175680041313], [0.35884571075439453, 0.07961022108793259, 0.489051878452301, 0.0672706812620163, 0.005221485160291195], [0.5333918333053589, 0.138141930103302, 0.08174044638872147, 0.2316247820854187, 0.015101072378456593], [0.334222674369812, 0.19875586032867432, 0.4456489384174347, 0.014890061691403389, 0.0064825210720300674], [0.026482226327061653, 0.8110326528549194, 0.15404333174228668, 0.004439415410161018, 0.00400238623842597], [0.29269829392433167, 0.017655812203884125, 0.044058818370103836, 0.6328455805778503, 0.012741444632411003], [0.23338274657726288, 0.02978355623781681, 0.18410660326480865, 0.531843900680542, 0.020883172750473022], [0.05453876778483391, 0.7268805503845215, 0.21156346797943115, 0.002378457225859165, 0.004638657905161381], [0.12255586683750153, 0.7913336753845215, 0.07486507296562195, 0.006085183937102556, 0.005160207394510508], [0.29978156089782715, 0.08677192777395248, 0.3415074348449707, 0.2499297857284546, 0.02200922928750515], [0.02052866481244564, 0.939950168132782, 0.032882384955883026, 0.00222292123362422, 0.004415674600750208], [0.24706946313381195, 0.15402662754058838, 0.436834454536438, 0.15447376668453217, 0.007595682982355356], [0.07390691339969635, 0.7712980508804321, 0.14425355195999146, 0.005321953445672989, 0.005219595041126013], [0.5045177936553955, 0.01023478526622057, 0.03391089290380478, 0.4362971782684326, 0.01503926794975996], [0.0325365848839283, 0.12423350661993027, 0.8320542573928833, 0.005970602389425039, 0.005205137189477682], [0.4480384290218353, 0.15360024571418762, 0.3582211434841156, 0.03214050829410553, 0.007999737747013569], [0.5542591214179993, 0.022251754999160767, 0.2315051257610321, 0.17962315678596497, 0.012360833585262299], [0.06691161543130875, 0.005117784719914198, 0.04022863879799843, 0.8710055351257324, 0.016736479476094246], [0.032206349074840546, 0.887308657169342, 0.07143570482730865, 0.004314734600484371, 0.00473451055586338], [0.40027955174446106, 0.008668106980621815, 0.024033552035689354, 0.55722975730896, 0.009789054282009602], [0.15538112819194794, 0.009979082271456718, 0.05271962657570839, 0.7661260962486267, 0.01579408161342144], [0.5600546002388, 0.034358613193035126, 0.06665210425853729, 0.32905909419059753, 0.009875629097223282], [0.07255357503890991, 0.8477904200553894, 0.05570173263549805, 0.019065452739596367, 0.0048888614401221275], [0.013005515560507774, 0.8937192559242249, 0.083348847925663, 0.004204889293760061, 0.005721477326005697], [0.2375190109014511, 0.05225439369678497, 0.26652854681015015, 0.43221181631088257, 0.011486276984214783], [0.5033897161483765, 0.23868189752101898, 0.21361038088798523, 0.03522781282663345, 0.009090177714824677], [0.3112340271472931, 0.014321176335215569, 0.06555341929197311, 0.5952396988868713, 0.01365172490477562], [0.018764154985547066, 0.6920594573020935, 0.26173028349876404, 0.01856412924826145, 0.008881919085979462], [0.07581904530525208, 0.30534330010414124, 0.5994895100593567, 0.013657732866704464, 0.005690385587513447], [0.026060620322823524, 0.8685289025306702, 0.09153227508068085, 0.007181093562394381, 0.006697116885334253], [0.4637329578399658, 0.019682221114635468, 0.02354547753930092, 0.4763280749320984, 0.016711309552192688], [0.3957173824310303, 0.049699585884809494, 0.06225595623254776, 0.470831960439682, 0.021495092660188675], [0.5613462328910828, 0.22289662063121796, 0.1375150978565216, 0.07289666682481766, 0.005345301236957312], [0.07544684410095215, 0.8286060690879822, 0.08377795666456223, 0.007668104954063892, 0.004500964656472206], [0.020703881978988647, 0.6470279693603516, 0.3252471387386322, 0.002315616002306342, 0.004705327562987804], [0.32911163568496704, 0.02819102443754673, 0.0448601059615612, 0.5823347568511963, 0.015502438880503178], [0.06679560989141464, 0.10164789855480194, 0.7825765609741211, 0.0394473522901535, 0.009532601572573185], [0.504086971282959, 0.39817115664482117, 0.0729939267039299, 0.016238655894994736, 0.008509310893714428], [0.8229049444198608, 0.07425591349601746, 0.0857304185628891, 0.013573671691119671, 0.003535096999257803], [0.8345048427581787, 0.07438652962446213, 0.06022784113883972, 0.024364301934838295, 0.006516491994261742], [0.5654357671737671, 0.37901732325553894, 0.04038824513554573, 0.008785638958215714, 0.0063730264082551], [0.03444213420152664, 0.6903462409973145, 0.26669228076934814, 0.004493841901421547, 0.00402547512203455], [0.16951943933963776, 0.18317870795726776, 0.5939099192619324, 0.04156189411878586, 0.011830039322376251], [0.8812857270240784, 0.023173166438937187, 0.021592091768980026, 0.06527659296989441, 0.008672420866787434], [0.1808534860610962, 0.00806964561343193, 0.038761477917432785, 0.7581194043159485, 0.014195905067026615], [0.8394772410392761, 0.10104992985725403, 0.04199151694774628, 0.013136209920048714, 0.004345118999481201], [0.7213003635406494, 0.023493358865380287, 0.11560627073049545, 0.13188527524471283, 0.0077147106640040874], [0.03883460909128189, 0.6399434208869934, 0.31475552916526794, 0.0028897770680487156, 0.003576757851988077], [0.4585685729980469, 0.3128926157951355, 0.1525130271911621, 0.05845336616039276, 0.017572300508618355], [0.473585844039917, 0.029201995581388474, 0.08715998381376266, 0.39399296045303345, 0.016059154644608498], [0.31958910822868347, 0.008060618303716183, 0.019022751599550247, 0.6354098916053772, 0.017917636781930923], [0.18425287306308746, 0.23749887943267822, 0.5084729194641113, 0.06264808773994446, 0.007127344608306885], [0.12550757825374603, 0.059249743819236755, 0.36132335662841797, 0.43698573112487793, 0.016933605074882507], [0.10552404820919037, 0.23373116552829742, 0.506446123123169, 0.13965800404548645, 0.014640673995018005], [0.4108034372329712, 0.01573232188820839, 0.046044718474149704, 0.5157521367073059, 0.011667358689010143], [0.18013761937618256, 0.15101328492164612, 0.4036012887954712, 0.2464466243982315, 0.018801216036081314], [0.02743477374315262, 0.924980878829956, 0.041468940675258636, 0.0021603917703032494, 0.0039550187066197395], [0.03755031153559685, 0.3944403827190399, 0.5551179051399231, 0.009178862906992435, 0.0037125039380043745], [0.6411045789718628, 0.16077721118927002, 0.08500304818153381, 0.10051102936267853, 0.01260420586913824], [0.03211281821131706, 0.9281381368637085, 0.03291608393192291, 0.0026945858262479305, 0.004138350952416658], [0.06804586201906204, 0.00731688691303134, 0.05889769643545151, 0.8472149968147278, 0.01852460764348507], [0.09105776250362396, 0.39216965436935425, 0.49932417273521423, 0.010682991705834866, 0.006765478290617466], [0.06764950603246689, 0.3275914192199707, 0.50986647605896, 0.08551930636167526, 0.009373368695378304], [0.0320114940404892, 0.7162259221076965, 0.24267524480819702, 0.00465705431997776, 0.004430227912962437], [0.3759820759296417, 0.015206064097583294, 0.02416222356259823, 0.5578362941741943, 0.02681335248053074], [0.4069925844669342, 0.1355123370885849, 0.3278783857822418, 0.11897526681423187, 0.010641409084200859], [0.5432872176170349, 0.03935259208083153, 0.19899144768714905, 0.20121139287948608, 0.017157403752207756], [0.12018069624900818, 0.12167103588581085, 0.7292189002037048, 0.024471228942275047, 0.004458199720829725], [0.48580417037010193, 0.041670892387628555, 0.4129200875759125, 0.05395969748497009, 0.005645092576742172], [0.11815406382083893, 0.008493172936141491, 0.07268206775188446, 0.7872942090034485, 0.013376420363783836], [0.5649407505989075, 0.01527467742562294, 0.1387384533882141, 0.2724347412586212, 0.008611376397311687], [0.03255853056907654, 0.43536707758903503, 0.5241352319717407, 0.003406275063753128, 0.004532915540039539], [0.09794874489307404, 0.2210063487291336, 0.574701189994812, 0.09515397250652313, 0.011189752258360386], [0.46549510955810547, 0.1444137692451477, 0.13308267295360565, 0.2492883801460266, 0.007720104418694973], [0.8804346323013306, 0.03262509033083916, 0.016954457387328148, 0.06166370213031769, 0.00832210574299097], [0.8093399405479431, 0.03264199197292328, 0.027379797771573067, 0.11788610368967056, 0.012752135284245014], [0.6018247604370117, 0.024526603519916534, 0.014075922779738903, 0.3386065661907196, 0.020966099575161934], [0.1870289444923401, 0.04097043722867966, 0.11463842540979385, 0.6240856647491455, 0.03327659144997597], [0.026367682963609695, 0.5092822909355164, 0.45740267634391785, 0.0030913164373487234, 0.003856043331325054], [0.49765193462371826, 0.05430729314684868, 0.19876225292682648, 0.2336450219154358, 0.01563357189297676], [0.043615467846393585, 0.8980797529220581, 0.041656043380498886, 0.008326047100126743, 0.008322649635374546], [0.018926454707980156, 0.1568339467048645, 0.8058547377586365, 0.012663391418755054, 0.005721323192119598], [0.7402280569076538, 0.15524506568908691, 0.06461472809314728, 0.033578578382730484, 0.006333531811833382], [0.07100491225719452, 0.040125008672475815, 0.2589944005012512, 0.6137773990631104, 0.0160982608795166], [0.17940326035022736, 0.7069743275642395, 0.059453219175338745, 0.04408798739314079, 0.010081303305923939], [0.5733651518821716, 0.24786128103733063, 0.15655715763568878, 0.016294382512569427, 0.005922038108110428]]\n",
      "0.3585781265050173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        cross_entropy_loss = train(model, train_dataloader, optimizer, scheduler, device, class_weights)\n",
    "        accuracy, report, probabilities = evaluate(model, val_dataloader, device)\n",
    "        print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "        print(report)\n",
    "        print(probabilities)\n",
    "        print(cross_entropy_loss)\n",
    "        loss_graph.append(cross_entropy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19caa7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a simple line plot\n",
    "plt.plot(loss_graph, marker='o', linestyle='-', color='blue')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Average Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "# Show the graph\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7ccc4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"data/bert_classifier_test.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ad618f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Herr Präsident! Herr Staatssekretär! Hohes Haus! Zu dieser hier angesprochenen Verunsicherung hat sicherlich nicht die Bundesregierung beigetragen, sondern zu einem Großteil haben die Streiks dazu beigetragen. Vorhin hat ja eine Kollegin gesagt, dass sich niemand von uns zu den Streiks geäußert hätte; ich kann das ja nun ein wenig tun. Ich würde gerne ein paar Pressestimmen hiezu bringen. Im „Kurier“ von heute heißt es: Der Streik ist vorbei, und nichts hat er gebracht. Bekanntlich hat der ÖGB die Gespräche abgebrochen und gemeint, streiken sei sinnvoller als verhandeln.“ Die „Presse“ schreibt: Der ÖGB wollte es wissen. Jetzt weiß er es. Die Österreicher sind nicht in eine Radikalisierung hineintreibbar. Damit ist auch das Gewicht des ÖGB zum Segen des Landes reduziert. In den „Oberösterreichische Nachrichten“ heißt es: Hätten nicht Fernsehen und Zeitungen so ausführlich berichtet, wäre der gestrige Streik an der Mehrheit der nicht auf öffentliche Verkehrsmittel angewiesenen Bürger beinahe spurlos vorüber gegangen. Die „Kronen Zeitung“ – das muss man sich vorstellen! – schreibt: Der Streik hat begonnen bei den ÖBB. Das ist jenes Unternehmen, wo die überwiegend pragmatisierten Mitarbeiter mit 52,6 Jahren in Pension gehen und wo bei bei den über 50-Jährigen im Schnitt 100 Krankenstandstage pro Jahr anfallen. Völlig klar, dass man dort gegen diesen Pensionsreformantrag zu Felde ziehen muss. Der „Standard“ schreibt: Eine Nichtreform des Pensionssystems wäre eine Ungerechtigkeit gegenüber den Jungen. Als Sportler weiß ich um meine Stellung in der Öffentlichkeit, und ich weiß auch, dass ich eine gewisse Vorbildwirkung habe. Ich glaube, als Erwachsene haben wir überhaupt großen Einfluss auf die jungen Leute, und wir haben auch verantwortliche Aufgaben. Einige haben wir auch hier in diesem Haus zu übernehmen – und eine davon ist, dafür zu sorgen, dass unsere Nachkommen ein aussichtsreiches Leben, auch ein gerechtes und soziales Pensionssystem zu erwarten haben, und dass wir für die jungen Menschen zumindest jene Rahmenbedingungen schaffen, von denen wir selbst uns vorstellen können, dass sie gut für unser eigenes Leben sind. Selbstverständlich sollten wir auch Vorbildwirkung für junge Menschen haben; Jugendliche sind ja immer irgendwie darauf bedacht, uns Erwachsene ein bisschen nachzuahmen. Ich glaube aber nicht, dass es im Sinne einer Vorbildwirkung ist, ihnen einzureden zu versuchen, dass Streiks konstruktiv seien, sondern wir sollten den jungen Menschen mitgeben, dass es sinnvoll ist, Probleme im Dialog zu lösen. Apropos Dialog: Da möchte ich ganz kurz auf die Ausführungen des Kollegen Broukal eingehen und skizzieren, wie dieser Dialog von Seiten der SPÖ hier betrieben wird. Und da gebe ich auch meiner Nachrednerin Melitta Trunk gleich ein bisschen Gesprächsstoff. In der „Kärntner Woche“ gibt es eine Anzeige der SPÖ, in der es heißt – ich zitiere –: „Nationalrat Lichtenegger ist dafür verantwortlich, dass wir 40 Prozent weniger Pensionen bekommen.“ Also eine bezahlte Lüge mit Steuergeldern! – Das ist nicht die Art von Dialog, die wir uns wünschen! – Danke schön. \n"
     ]
    }
   ],
   "source": [
    "print(train_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8fdb00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Österreich muss aktiv in erneuerbare Energien investieren um unsere Umwelt zu schützen.\n",
      "Predicted party: 1\n",
      "Wir müssen die Zuwanderung stoppen um unseren Leuten ein gutes Österreich zu ermöglichen.\n",
      "Predicted party: 1\n",
      "Für eine gerechte Gesellschaft braucht es mehr Umverteilung von oben nach unten.\n",
      "Predicted party: 1\n",
      "Leistung muss sich wieder lohnen. Wer hart arbeitet, soll gut leben.\n",
      "Predicted party: 1\n"
     ]
    }
   ],
   "source": [
    "# Test party classification.\"\n",
    "test_text= \"Österreich muss aktiv in erneuerbare Energien investieren um unsere Umwelt zu schützen.\"\n",
    "test_text1= \"Wir müssen die Zuwanderung stoppen um unseren Leuten ein gutes Österreich zu ermöglichen.\"\n",
    "test_text2= \"Für eine gerechte Gesellschaft braucht es mehr Umverteilung von oben nach unten.\"\n",
    "test_text3= \"Leistung muss sich wieder lohnen. Wer hart arbeitet, soll gut leben.\"\n",
    "party = predict_party(test_text, model, tokenizer, device)\n",
    "party1 = predict_party(test_text1, model, tokenizer, device)\n",
    "party2 = predict_party(test_text2, model, tokenizer, device)\n",
    "party3 = predict_party(test_text3, model, tokenizer, device)\n",
    "print(test_text)\n",
    "print(f\"Predicted party: {party}\")\n",
    "print(test_text1)\n",
    "print(f\"Predicted party: {party1}\")\n",
    "print(test_text2)\n",
    "print(f\"Predicted party: {party2}\")\n",
    "print(test_text3)\n",
    "print(f\"Predicted party: {party3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e6ab1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      " Herr Präsident! Herr Bundesminister! Geschätztes Hohes Haus! Herr Abgeordneter Wittauer, gerne würden wir dieses Gesetz unterstützen, wir haben das ja bereits im Ausschuss ziemlich ausführlich erörtert und einige positive Dinge auch positiv angemerkt. Es sind darin ja auch immerhin Anregungen der Grünen aufgenommen worden, so zum Beispiel eine Bestandsaufnahme über den Zustand der Gewässer, was ja auch in der Wasserrahmenrichtlinie vorgesehen ist. Weiters: Ausmaß der Belastungen, Erhalt und Verbesserung des Zustands, aber, wie Kollegin Glawischnig schon erwähnt hat: nichts vom ökologischen Hochwasserschutz ist darin enthalten! HQ 100 wird nicht eingehalten, sondern das geht zurück auf HQ 30, obwohl auch die Salzburger sehr dafür gewesen wären. Der besondere Schutz der österreichischen Wasserressourcen, den Sie, Frau Kollegin Achleitner, ja auch angesprochen haben, wurde in der Ausschusssitzung nicht besonders positiv beurteilt. Unser Entschließungsantrag wurde zwar zur Kenntnis genommen, aber nicht unterstützt – und wird vermutlich auch nicht unterstützt werden. So viel dazu. Und ich kann nur sagen: schade, schade, schade! Man kann ja nicht immer nur von den anderen erwarten, dass sie bei allem mitmachen, selber möchte man allerdings sozusagen nur das eigene Ei bebrüten. Realität ist viel mehr, dass wir einen sehr guten Zustand unseres Trinkwassers haben, ganz im Gegensatz zu den Verhältnissen, unter denen viele Menschen auf dieser Erde leben müssen. 1,4 Milliarden Menschen haben keinen Zugang zu Trinkwasser; 2 Milliarden Menschen haben nur Zugang zu qualitativ schlechtem Trinkwasser. Deshalb haben wir auch unseren Entschließungsantrag zum Thema GATS mit eingebracht, um zu verhindern, dass im Rahmen dieser Dienstleistungsverhandlungen ein Ausverkauf österreichischer Wasserressourcen stattfindet. Ich halte sehr viel davon, wenn das Know-how, wenn das Wissen der Österreicher diesbezüglich auch an andere Staaten weiter gegeben wird, aber wir müssen auch bei uns selbst anfangen. Realität ist beispielsweise, dass in Niederösterreich das Grundwasser wie eh und je mit Nitrat belastet ist und viele Menschen nitrat-belastetes Trinkwasser nutzen müssen. Davor können wir auch nicht die Augen verschließen! Deshalb muss ich leider sagen: Realität ist auch, dass die Genehmigung von grundwasserbeeinträchtigenden Projekten betroffener LandwirtInnen von den Landesbehörden übergangen beziehungsweise diese Menschen ausgeschlossen wurden. Es war uns auch ein großes Anliegen, dass die Öffentlichkeit der Verfahren gewahrt bleibt. – In ganz zentralen Dingen konnten wir also keine Einigung erreichen! Sie von den Regierungsparteien müssen ganz einfach zur Kenntnis nehmen: Sie können nicht von uns etwas erwarten, was Sie selbst in keiner Weise mit Anträgen seitens der Grünen machen. – Danke schön.  \n",
      "Predicted party: 0\n",
      "3\n",
      " Sehr geehrter Herr Präsident! Sehr geehrter Herr Bundeskanzler! Sehr geehrter Herr Finanzminister! Herr Verkehrsminister! Sehr geehrter Herr Staatssekretär! Meine Damen und Herren! Hohes Haus! Klar in der heutigen Debatte ist geworden, dass Sie uns hier ein perfides Doppelspiel vorführen. Sie haben immer wieder darauf hingewiesen, dass Sie österreichische Kernaktionäre haben wollen, aber Sie haben nicht darauf hingewiesen, dass es keine Garantie dafür gibt, dass die österreichischen Kernaktionäre die Aktien auch behalten. Wer, Herr Bundeskanzler, sagt Ihnen denn, dass Herr Direktor Scharinger auf Grund irgendeiner Entwicklung nicht gezwungen ist, schon morgen zu verkaufen? Wir wollen einen Kernaktionär in staatlicher Hand, denn da haben wir Sicherheit. Die Voest und ihre MitarbeiterInnen verdienen Sicherheit, genauso wie die oberösterreichische Wirtschaft, die Zulieferbetriebe Sicherheit und Garantie verdienen. Deshalb verstehe ich nicht, dass 15 oberösterreichische Abgeordnete der Regierungsfraktionen diesen Antrag der Bundesregierung, der die Zukunft in völlige Unsicherheit hüllt, mittragen werden. Herr Kollege Mitterlehner! Die Zulieferbetriebe, Klein- und Mittelbetriebe, von der Voest abhängig – wie schaut ihre Zukunft aus, wenn es keine österreichischen Kernaktionäre mehr gibt? Können Sie garantieren, dass morgen, übermorgen, dass nächstes Jahr, dass in zehn Jahren nach wie vor das Österreich-Paket überwiegt? Geben Sie mir die Garantie dafür? Herr Bürgermeister – ich weiß, es gibt viele Bürgermeister hier –, Herr Bürgermeister Ellmauer! Garantieren Sie mir, dass die Oberösterreich-Lösung eine OberösterreichLösung bleibt? Meines Erachtens – und das ist deutlich zu dokumentieren – ist die Oberösterreich-Lösung eine glatte Repolitisierung auf Landesebene. Wer steckt denn hinter den Investoren? – Diese Investoren sind eindeutig der ÖVP zuzurechnen – die Banken, teilweise die Versicherungen; die Oberösterreichische Versicherung ist ja sowieso eine Vorfeldorganisation der ÖVP und mehr oder weniger auch ein Mitträger des Landeshauptmannes Pühringer und seiner Politik! Und diese Oberösterreich-Lösung – oder die Österreich-Lösung, wie der Herr Bundeskanzler sagt – hat einen ganz massiven Pferdefuß: Sie garantiert keine Sicherheit, sie garantiert keine Zukunft für die Betriebe in österreichischer Hand, und sie setzt die Voest in ihrer jetzigen offensiven Börsesituation mehr oder weniger in ihrer Zukunft auf Sand. Und das ist unser Problem: Sie setzen die Voest auf Sand, auf ungewisse Zukunftsperspektiven! Nun noch ganz konkret auch die Frage: Wenn Sie über die Börse verkaufen, wer wird denn dann sozusagen mit Strohmännern mitbieten? – Es ist ja nicht garantiert, dass gewisse Fonds nicht doch gewisse Drähte zu Magna haben, dass nicht doch im Hintergrund Frank Stronach am Werk ist und dass er dann nicht doch durch gewisse Einkaufsmöglichkeiten von anonymen Aktionären letztlich strategische Mehrheiten bilden kann. Das ist nicht auszuschließen, und dagegen verwahren wir uns! Deshalb darf ich in aller Prägnanz folgenden Antrag einbringen: Entschließungsantrag der Abgeordneten Kogler, Sburny, Kolleginnen und Kollegen betreffend Sicherheitsbeschluss gegen den Ausverkauf der voestalpine AG Der Nationalrat wolle beschließen: Die Bundesregierung wird aufgefordert den Privatisierungsauftrag an die Österreichische Industrieholding AG betreffend die voestalpine AG dahingehend abzuändern, dass zumindest 25 Prozent plus eine Aktie als Sperrminorität vorerst von der ÖIAG nicht verkauft werden. ***** Nicht verkaufen, das ist das Schlüsselwort, denn das bedeutet Sicherheit – und darauf kommt es an! – Danke schön.  \n",
      "Predicted party: 0\n",
      "1\n",
      " Herr Präsident! Meine Damen und Herren! Hohes Haus! Der Gesetzesantrag 128/A steht zur Diskussion, der jetzt begründet wurde, in dem es darum geht, mehr Mitarbeiter einzustellen. Ich denke, dass es wichtig ist, dazu einige Dinge festzustellen. Erstens: Österreich ist bei der Vollziehung des Datenschutzes beispielgebend. Wir haben seit 1979 ein Datenschutzgesetz. Wir waren immer Vorreiter. Das waren die anderen europäischen Staaten bei weitem nicht. Die Datenschutzrichtlinie der EU liegt weit unter dem österreichischen Niveau. Vor allem romanische Länder, aber auch die USA sind weit entfernt von jenem Status, der bei uns Norm ist. Österreich schafft es, mit wenig Personalaufwand ein hohes Maß an Sicherheit zu bieten. Es wird effizient gearbeitet. Es geht nicht nur darum, Mitarbeiter einzustellen, sondern darum, einen bestmöglichen Output zu erreichen. In Österreich gelingt dies in beispielgebender Art und Weise. Daher möchte ich heute und hier bei dieser ersten Lesung allen Mitarbeitern und Beamten herzlichen Dank aussprechen und auch klarmachen, dass sie Großartiges leisten. Wir werden diesen Antrag im Ausschuss sicherlich weiter beraten.  \n",
      "Predicted party: 1\n",
      "2\n",
      " Geschätzter Herr Präsident! Geschätzter Herr Staatssekretär! Meine Damen und Herren Abgeordneten! Ich hätte eigentlich, wenn es aus formalen Gründen nicht richtig wäre, nichts dagegen gehabt, wenn dieses Schild stehen geblieben wäre, denn: Stinker, wo sie auch überall sein mögen, auf der Straße oder sonst wo, habe ich auch nicht gerne, und ich bin durchaus dazu bereit, ein Verbot für solche LKW auszusprechen. Da sind wir auf der gleichen Linie, Frau Abgeordnete. Als ich die Schilder mit den LKW-Fahrverboten, die hier gezeigt wurden, bei Ihnen gesehen habe, ist mir schon in den Sinn gekommen, dass Sie heute Früh wohl Ihre Zeitung gelesen, eine frische Semmel, vielleicht auch ein Müsli oder ein Knäckebrot gegessen haben und sich dabei vielleicht auch der Tatsache bewusst gewesen sind, dass all das vermutlich nicht mit dem Flugzeug, nicht mit der Bahn, nicht mit der Straßenbahn und auch nicht mit dem Schiff von A nach B transportiert wurde, sondern dass es schon Transporte mit dem LKW, mit dem Klein-LKW braucht, um eben den Wohlstand, den wir auch gerne genießen, sicherzustellen. Meine Damen und Herren! Was ich einleitend damit sagen möchte, ist einfach nur die Feststellung – bei aller Sensibilität für dieses Thema, die auch ich habe, glauben Sie mir das! –: Es ist falsch, wenn man wieder beginnt, den LKW, die Straße, den Straßenverkehr gegen andere Verkehrsträger auszuspielen! Das ist falsch! Wir müssen alles tun, damit wir so wenig LKW-Verkehr wie möglich auf der Straße haben, damit wir so viele Güter wie möglich auf der Schiene transportieren, aber wir dürfen diese beiden Verkehrsträger nicht gegeneinander ausspielen, sondern wir müssen schauen, dass wir sie sinnvoll kombinieren. Dann ist gewährleistet, dass die Wirtschaft ihre Wege hat, dann ist gewährleistet, dass Sie und ich und wir alle auch die Waren, die wir brauchen, bekommen. Dann ist auch gewährleistet, dass wir eine vernünftige Verkehrspolitik in diesem Lande diskutieren können. Frau Abgeordnete, Sie wissen ganz genau, dass ich mich sehr vehement dafür eingesetzt habe, das der auslaufende Transitvertrag eine Verlängerung in Form einer Übergangslösung erfährt, und Sie wissen auch ganz genau, dass ich mich sehr vehement in Brüssel dafür eingesetzt habe, dass die Wegekostenrichtlinie, die uns versprochen wurde, jetzt endlich zumindest in die Diskussionsphase kommt. Das Erstere ist noch in Verhandlung. Ich habe in bilateralen Gesprächen zumindest erreicht, dass mein Amtskollege Lunardi alles tut, um Verzögerungen hintanzuhalten. Er tut das, er hält Wort: Er hat die Arbeitsgruppe ablaufen lassen. Er hat dafür gesorgt, dass es am 22. September als A-Punkt im Wettbewerbsrat behandelt wurde und somit formell in das Vermittlungsverfahren eingestiegen werden kann, und er hat auch die anderen Schritte gemeinsam mit mir abgestimmt und beschleunigt. Wir haben diesen Weg am 10. September vorgezeichnet und gleichzeitig, parallel dazu, vereinbart, noch einmal Kompromisse zu suchen, unabhängig vom Vermittlungsverfahren. Sie wissen aber auch, dass man es vor über 10 Jahren eben verabsäumt hat, eine Nachfolgeregelung oder eine Verlängerungsregelung zu vereinbaren und wir deshalb jetzt aus Sicht der anderen zumindest in einer rechtlich nicht günstigen Position sind. Wir kämpfen trotzdem bis zur letzten Sekunde, Frau Abgeordnete, das können Sie mir glauben! Dazu brauche ich auch keine Aktuelle Stunde im Parlament, das tue ich auf jeden Fall. Ich habe in Tirol – und dazu stehe ich! – gesagt, dass ich für eine Nachfolgeregelung kämpfen werde, nicht nur, wie es sich für einen österreichischen Verkehrsminister gehört, nicht nur, wie es sich für einen Bürger gehört, dem die Umwelt, dem die Gesundheit der Mitmenschen etwas wert ist, sondern ich werde so kämpfen, als wäre ich ein betroffener Tiroler. Glauben Sie mir das! Glauben Sie mir weiters, dass auch im Hinblick auf den Transit, der in Tirol ein Ausmaß angenommen hat, das wirklich nicht zumutbar ist, wir uns auch Gedanken darüber machen, wie wir innerstaatlich Verbesserungen vornehmen können. Glauben Sie mir, es war kein Zufall, dass ich am 20. August, nachdem ich die Sommerzeit genutzt und mir darüber Gedanken gemacht habe, in Tirol ein Modell vorgestellt habe, das nicht die endgültige Lösung, aber zumindest ein Tropfen auf dem heißen Stein ist. Ich halte es nämlich für gescheit, Verkehrsbeeinflussungsanlagen erstens überhaupt möglichst bald zu installieren, da wir dadurch jenen Verkehr, der unvermeidbar ist, besser managen können, und zweitens diese Verkehrsbeeinflussungsanlagen, die mit einem Investitionsvolumen von 200 Millionen € bis 2008 österreichweit installiert sein werden, zunächst an die Immissionsmessstellen insbesondere in den sensiblen Gebieten zu koppeln. Ich habe deshalb versprochen, dass der Realisierungsauftrag in der Größenordung von 30 Millionen € noch im September von mir vergeben wird, dass die Verkehrsbeeinflussungsanlage im Großraum Innsbruck als Erste realisiert und bis Ende nächsten Jahres fertig sein wird, sodass dann Möglichkeiten bestehen, sobald der Schadstoffausstoß, die Luftverschmutzung, die gesamte Problematik einen gewissen Grenzwert erreicht, zu reagieren, indem ich Fahrverbote für bestimmte LKW-Klassen, zum Beispiel Euro 0, Euro 1 und Euro 2, ausspreche, indem ich Maßnahmen setze wie etwa eine Geschwindigkeitsreduktion, wenn dadurch gewährleistet ist, dass sich die Luftverschmutzung reduziert und Ähnliches mehr. – Ich halte das für eine Idee, die zumindest verfolgenswert ist. Wir werden sehen, was sie bringt. Ich halte es aber auch für notwendig, geschätzte Kollegin, dass wir auch weiterhin dafür kämpfen und Anreize schaffen, dass die Gütertransporte der LKW auf die Schiene verlagert werden. Dazu muss ich schon erwähnen, dass – Sie nehmen das meist einfach nur zur Kenntnis – es nicht so einfach war, am 10. September gemeinsam mit Kollegen Lunardi ein Memorandum zu unterschreiben, das nun die Phase 2 des Baus des Brenner-Basistunnels festlegt, also was die Finanzierung betrifft, was die technische Machbarkeit betrifft, was die Vorbereitung des Staatsvertrages betrifft, was die Abwicklung im Detail, das Zeitmanagement, betrifft, sodass der Brenner-Basistunnel bis 2006 baureif sein soll. Es ist alles genau, detailliert festgelegt, und damit wurden auch bereits 90 Millionen € freigegeben – 50 Prozent bezahlt die EU, den Rest teilen sich Italien und Österreich. Mit diesen 90 Millionen € wird detaillierter geplant, werden Probebohrungen vorgenommen, werden Verhandlungen geführt, werden Finanzierungsmodelle erstellt und Ähnliches mehr. Wir gehen also einen großen Schritt weiter in Richtung Verlagerung auf die Schiene. Nehmen Sie das, bitte, auch einmal positiv zur Kenntnis! Seien Sie einmal gut gewillt und erkennen Sie, dass diese österreichische Bundesregierung, dass dieser österreichische Verkehrsminister die Problematik, die Sensibilität, auch den Zeitdruck erkannt hat und alles dafür tut – in Österreich, in Tirol, in Italien, in Brüssel –, um die Situation, insbesondere jene der Anrainer, und zwar nicht nur in Tirol, sondern auch am Pyhrnpass, auch am Tauernpass, zu verbessern und die Lebensqualität wieder halbwegs so zu gestalten, dass sie verträglich, dass sie gut, dass sie auch geeignet ist, sich darüber zu freuen, wenn man dort wohnt. Noch etwas, das mir nicht unwichtig erscheint, weil ich versprochen habe, das bei jeder Gelegenheit zu sagen: Wissen Sie, was mich betroffen macht? – Mich machen auch jene Auswirkungen des österreichischen LKW-Verkehrs, und zwar nicht nur des Transitverkehrs, sondern insgesamt, betroffen, die im Bericht der WHO nachzulesen sind – sie werden ihn kennen, er ist unbestritten und unwidersprochen –, wonach aufgrund des Schadstoffausstoßes der österreichischen LKW pro Jahr 2400 vorzeitige Todesfälle zu verzeichnen sind, 2700 zusätzliche Fälle von chronischer Bronchitis bei Erwachsenen, 20 600 zusätzliche Fälle von chronischer Bronchitis bei Kindern unter 15 Jahren und 1,3 Millionen zusätzliche Krankenstandstage zu verzeichnen sind. Das kann man nicht oft genug erwähnen! Wissen Sie, wem ich das zuletzt, nämlich gestern, erzählt habe? – Herrn Riccardo Illy, dem Präsidenten der Region Friaul-Julisch Venetien, der mich besucht hat und ebenfalls mit mir über mehr Ökopunkte reden wollte und darüber, warum wir das denn nicht endlich alles vergessen, wir sollten doch den freien Warenverkehr forcieren. Ich habe ihm diese Zahlen gesagt, und damit war das Gespräch auf einer anderen Ebene, weil ihn das eben auch betroffen macht. Also: Wir tun ohnehin alles, was man tun kann. Helfen Sie uns! Packen wir das gemeinsam an! Frau Kollegin, es wäre sehr dienlich gewesen, wenn auch Ihre Fraktion im EU-Parlament dem Caveri-Bericht nicht zugestimmt, sondern die österreichischen Interessen vertreten hätte. Das war aber nicht der Fall. Vielleicht gelingt es jetzt, im Vermittlungsverfahren die österreichischen Interessen dort gemeinsam zu vertreten. Ich bin für ein gemeinsames Vorgehen immer zu haben, habe bereits wieder Termine mit den wichtigen Entscheidungsträgern in diesem Vermittlungsverfahren, mit den österreichischen Delegierten im EU-Parlament, denn mir ist die Sensibilität der Transitproblematik sehr wohl bekannt. Mir kann man jedenfalls nicht vorwerfen, dass ich das bagatellisiere. Es ist aber auch klar: Ich werde die Situation rund um die LKW und den Transit auf der Straße niemals ausnützen, um die Leute gegen die Wirtschaft aufzuhetzen, um mit durchaus berechtigten Anliegen Arbeitsplätze zu gefährden. Wir brauchen alles! Es gehört zur Lebensqualität auch ein Arbeitsplatz, auch ein Transport von A nach B – und eben eine gesunde Umwelt. Wir werden das Beste tun, damit wir das bestmöglich unter einen Hut bringen. 9.28 \n",
      "Predicted party: 1\n"
     ]
    }
   ],
   "source": [
    "# Test party classification.\"\n",
    "test_text= train_texts[0]\n",
    "test_text1= train_texts[1]\n",
    "test_text2= train_texts[2]\n",
    "test_text3= train_texts[3]\n",
    "party = predict_party(test_text, model, tokenizer, device)\n",
    "party1 = predict_party(test_text1, model, tokenizer, device)\n",
    "party2 = predict_party(test_text2, model, tokenizer, device)\n",
    "party3 = predict_party(test_text3, model, tokenizer, device)\n",
    "print(train_labels[0])\n",
    "print(test_text)\n",
    "print(f\"Predicted party: {party}\")\n",
    "print(train_labels[1])\n",
    "print(test_text1)\n",
    "print(f\"Predicted party: {party1}\")\n",
    "print(train_labels[2])\n",
    "print(test_text2)\n",
    "print(f\"Predicted party: {party2}\")\n",
    "print(train_labels[3])\n",
    "print(test_text3)\n",
    "print(f\"Predicted party: {party3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b20719",
   "metadata": {},
   "source": [
    "if training data is not being predicted it needs more epochs\n",
    "-> training data exactly with the same truncation as training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c2f54dae",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 3 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mTfidfDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m TfidfDataset(val_texts, val_labels, tokenizer, max_length)\n\u001b[0;32m      3\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() takes 3 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "train_dataset = TfidfDataset(train_texts, train_labels, tokenizer, max_length)\n",
    "val_dataset = TfidfDataset(val_texts, val_labels, tokenizer, max_length)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970ff8e6",
   "metadata": {},
   "source": [
    "rather scikit learn w/o pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d81a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"data/logreg_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ddf55c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      " Herr Präsident! Herr Bundesminister! Geschätztes Hohes Haus! Herr Abgeordneter Wittauer, gerne würden wir dieses Gesetz unterstützen, wir haben das ja bereits im Ausschuss ziemlich ausführlich erörtert und einige positive Dinge auch positiv angemerkt. Es sind darin ja auch immerhin Anregungen der Grünen aufgenommen worden, so zum Beispiel eine Bestandsaufnahme über den Zustand der Gewässer, was ja auch in der Wasserrahmenrichtlinie vorgesehen ist. Weiters: Ausmaß der Belastungen, Erhalt und Verbesserung des Zustands, aber, wie Kollegin Glawischnig schon erwähnt hat: nichts vom ökologischen Hochwasserschutz ist darin enthalten! HQ 100 wird nicht eingehalten, sondern das geht zurück auf HQ 30, obwohl auch die Salzburger sehr dafür gewesen wären. Der besondere Schutz der österreichischen Wasserressourcen, den Sie, Frau Kollegin Achleitner, ja auch angesprochen haben, wurde in der Ausschusssitzung nicht besonders positiv beurteilt. Unser Entschließungsantrag wurde zwar zur Kenntnis genommen, aber nicht unterstützt – und wird vermutlich auch nicht unterstützt werden. So viel dazu. Und ich kann nur sagen: schade, schade, schade! Man kann ja nicht immer nur von den anderen erwarten, dass sie bei allem mitmachen, selber möchte man allerdings sozusagen nur das eigene Ei bebrüten. Realität ist viel mehr, dass wir einen sehr guten Zustand unseres Trinkwassers haben, ganz im Gegensatz zu den Verhältnissen, unter denen viele Menschen auf dieser Erde leben müssen. 1,4 Milliarden Menschen haben keinen Zugang zu Trinkwasser; 2 Milliarden Menschen haben nur Zugang zu qualitativ schlechtem Trinkwasser. Deshalb haben wir auch unseren Entschließungsantrag zum Thema GATS mit eingebracht, um zu verhindern, dass im Rahmen dieser Dienstleistungsverhandlungen ein Ausverkauf österreichischer Wasserressourcen stattfindet. Ich halte sehr viel davon, wenn das Know-how, wenn das Wissen der Österreicher diesbezüglich auch an andere Staaten weiter gegeben wird, aber wir müssen auch bei uns selbst anfangen. Realität ist beispielsweise, dass in Niederösterreich das Grundwasser wie eh und je mit Nitrat belastet ist und viele Menschen nitrat-belastetes Trinkwasser nutzen müssen. Davor können wir auch nicht die Augen verschließen! Deshalb muss ich leider sagen: Realität ist auch, dass die Genehmigung von grundwasserbeeinträchtigenden Projekten betroffener LandwirtInnen von den Landesbehörden übergangen beziehungsweise diese Menschen ausgeschlossen wurden. Es war uns auch ein großes Anliegen, dass die Öffentlichkeit der Verfahren gewahrt bleibt. – In ganz zentralen Dingen konnten wir also keine Einigung erreichen! Sie von den Regierungsparteien müssen ganz einfach zur Kenntnis nehmen: Sie können nicht von uns etwas erwarten, was Sie selbst in keiner Weise mit Anträgen seitens der Grünen machen. – Danke schön.  \n",
      "Predicted party: 0\n",
      "3\n",
      " Sehr geehrter Herr Präsident! Sehr geehrter Herr Bundeskanzler! Sehr geehrter Herr Finanzminister! Herr Verkehrsminister! Sehr geehrter Herr Staatssekretär! Meine Damen und Herren! Hohes Haus! Klar in der heutigen Debatte ist geworden, dass Sie uns hier ein perfides Doppelspiel vorführen. Sie haben immer wieder darauf hingewiesen, dass Sie österreichische Kernaktionäre haben wollen, aber Sie haben nicht darauf hingewiesen, dass es keine Garantie dafür gibt, dass die österreichischen Kernaktionäre die Aktien auch behalten. Wer, Herr Bundeskanzler, sagt Ihnen denn, dass Herr Direktor Scharinger auf Grund irgendeiner Entwicklung nicht gezwungen ist, schon morgen zu verkaufen? Wir wollen einen Kernaktionär in staatlicher Hand, denn da haben wir Sicherheit. Die Voest und ihre MitarbeiterInnen verdienen Sicherheit, genauso wie die oberösterreichische Wirtschaft, die Zulieferbetriebe Sicherheit und Garantie verdienen. Deshalb verstehe ich nicht, dass 15 oberösterreichische Abgeordnete der Regierungsfraktionen diesen Antrag der Bundesregierung, der die Zukunft in völlige Unsicherheit hüllt, mittragen werden. Herr Kollege Mitterlehner! Die Zulieferbetriebe, Klein- und Mittelbetriebe, von der Voest abhängig – wie schaut ihre Zukunft aus, wenn es keine österreichischen Kernaktionäre mehr gibt? Können Sie garantieren, dass morgen, übermorgen, dass nächstes Jahr, dass in zehn Jahren nach wie vor das Österreich-Paket überwiegt? Geben Sie mir die Garantie dafür? Herr Bürgermeister – ich weiß, es gibt viele Bürgermeister hier –, Herr Bürgermeister Ellmauer! Garantieren Sie mir, dass die Oberösterreich-Lösung eine OberösterreichLösung bleibt? Meines Erachtens – und das ist deutlich zu dokumentieren – ist die Oberösterreich-Lösung eine glatte Repolitisierung auf Landesebene. Wer steckt denn hinter den Investoren? – Diese Investoren sind eindeutig der ÖVP zuzurechnen – die Banken, teilweise die Versicherungen; die Oberösterreichische Versicherung ist ja sowieso eine Vorfeldorganisation der ÖVP und mehr oder weniger auch ein Mitträger des Landeshauptmannes Pühringer und seiner Politik! Und diese Oberösterreich-Lösung – oder die Österreich-Lösung, wie der Herr Bundeskanzler sagt – hat einen ganz massiven Pferdefuß: Sie garantiert keine Sicherheit, sie garantiert keine Zukunft für die Betriebe in österreichischer Hand, und sie setzt die Voest in ihrer jetzigen offensiven Börsesituation mehr oder weniger in ihrer Zukunft auf Sand. Und das ist unser Problem: Sie setzen die Voest auf Sand, auf ungewisse Zukunftsperspektiven! Nun noch ganz konkret auch die Frage: Wenn Sie über die Börse verkaufen, wer wird denn dann sozusagen mit Strohmännern mitbieten? – Es ist ja nicht garantiert, dass gewisse Fonds nicht doch gewisse Drähte zu Magna haben, dass nicht doch im Hintergrund Frank Stronach am Werk ist und dass er dann nicht doch durch gewisse Einkaufsmöglichkeiten von anonymen Aktionären letztlich strategische Mehrheiten bilden kann. Das ist nicht auszuschließen, und dagegen verwahren wir uns! Deshalb darf ich in aller Prägnanz folgenden Antrag einbringen: Entschließungsantrag der Abgeordneten Kogler, Sburny, Kolleginnen und Kollegen betreffend Sicherheitsbeschluss gegen den Ausverkauf der voestalpine AG Der Nationalrat wolle beschließen: Die Bundesregierung wird aufgefordert den Privatisierungsauftrag an die Österreichische Industrieholding AG betreffend die voestalpine AG dahingehend abzuändern, dass zumindest 25 Prozent plus eine Aktie als Sperrminorität vorerst von der ÖIAG nicht verkauft werden. ***** Nicht verkaufen, das ist das Schlüsselwort, denn das bedeutet Sicherheit – und darauf kommt es an! – Danke schön.  \n",
      "Predicted party: 4\n",
      "1\n",
      " Herr Präsident! Meine Damen und Herren! Hohes Haus! Der Gesetzesantrag 128/A steht zur Diskussion, der jetzt begründet wurde, in dem es darum geht, mehr Mitarbeiter einzustellen. Ich denke, dass es wichtig ist, dazu einige Dinge festzustellen. Erstens: Österreich ist bei der Vollziehung des Datenschutzes beispielgebend. Wir haben seit 1979 ein Datenschutzgesetz. Wir waren immer Vorreiter. Das waren die anderen europäischen Staaten bei weitem nicht. Die Datenschutzrichtlinie der EU liegt weit unter dem österreichischen Niveau. Vor allem romanische Länder, aber auch die USA sind weit entfernt von jenem Status, der bei uns Norm ist. Österreich schafft es, mit wenig Personalaufwand ein hohes Maß an Sicherheit zu bieten. Es wird effizient gearbeitet. Es geht nicht nur darum, Mitarbeiter einzustellen, sondern darum, einen bestmöglichen Output zu erreichen. In Österreich gelingt dies in beispielgebender Art und Weise. Daher möchte ich heute und hier bei dieser ersten Lesung allen Mitarbeitern und Beamten herzlichen Dank aussprechen und auch klarmachen, dass sie Großartiges leisten. Wir werden diesen Antrag im Ausschuss sicherlich weiter beraten.  \n",
      "Predicted party: 0\n",
      "2\n",
      " Geschätzter Herr Präsident! Geschätzter Herr Staatssekretär! Meine Damen und Herren Abgeordneten! Ich hätte eigentlich, wenn es aus formalen Gründen nicht richtig wäre, nichts dagegen gehabt, wenn dieses Schild stehen geblieben wäre, denn: Stinker, wo sie auch überall sein mögen, auf der Straße oder sonst wo, habe ich auch nicht gerne, und ich bin durchaus dazu bereit, ein Verbot für solche LKW auszusprechen. Da sind wir auf der gleichen Linie, Frau Abgeordnete. Als ich die Schilder mit den LKW-Fahrverboten, die hier gezeigt wurden, bei Ihnen gesehen habe, ist mir schon in den Sinn gekommen, dass Sie heute Früh wohl Ihre Zeitung gelesen, eine frische Semmel, vielleicht auch ein Müsli oder ein Knäckebrot gegessen haben und sich dabei vielleicht auch der Tatsache bewusst gewesen sind, dass all das vermutlich nicht mit dem Flugzeug, nicht mit der Bahn, nicht mit der Straßenbahn und auch nicht mit dem Schiff von A nach B transportiert wurde, sondern dass es schon Transporte mit dem LKW, mit dem Klein-LKW braucht, um eben den Wohlstand, den wir auch gerne genießen, sicherzustellen. Meine Damen und Herren! Was ich einleitend damit sagen möchte, ist einfach nur die Feststellung – bei aller Sensibilität für dieses Thema, die auch ich habe, glauben Sie mir das! –: Es ist falsch, wenn man wieder beginnt, den LKW, die Straße, den Straßenverkehr gegen andere Verkehrsträger auszuspielen! Das ist falsch! Wir müssen alles tun, damit wir so wenig LKW-Verkehr wie möglich auf der Straße haben, damit wir so viele Güter wie möglich auf der Schiene transportieren, aber wir dürfen diese beiden Verkehrsträger nicht gegeneinander ausspielen, sondern wir müssen schauen, dass wir sie sinnvoll kombinieren. Dann ist gewährleistet, dass die Wirtschaft ihre Wege hat, dann ist gewährleistet, dass Sie und ich und wir alle auch die Waren, die wir brauchen, bekommen. Dann ist auch gewährleistet, dass wir eine vernünftige Verkehrspolitik in diesem Lande diskutieren können. Frau Abgeordnete, Sie wissen ganz genau, dass ich mich sehr vehement dafür eingesetzt habe, das der auslaufende Transitvertrag eine Verlängerung in Form einer Übergangslösung erfährt, und Sie wissen auch ganz genau, dass ich mich sehr vehement in Brüssel dafür eingesetzt habe, dass die Wegekostenrichtlinie, die uns versprochen wurde, jetzt endlich zumindest in die Diskussionsphase kommt. Das Erstere ist noch in Verhandlung. Ich habe in bilateralen Gesprächen zumindest erreicht, dass mein Amtskollege Lunardi alles tut, um Verzögerungen hintanzuhalten. Er tut das, er hält Wort: Er hat die Arbeitsgruppe ablaufen lassen. Er hat dafür gesorgt, dass es am 22. September als A-Punkt im Wettbewerbsrat behandelt wurde und somit formell in das Vermittlungsverfahren eingestiegen werden kann, und er hat auch die anderen Schritte gemeinsam mit mir abgestimmt und beschleunigt. Wir haben diesen Weg am 10. September vorgezeichnet und gleichzeitig, parallel dazu, vereinbart, noch einmal Kompromisse zu suchen, unabhängig vom Vermittlungsverfahren. Sie wissen aber auch, dass man es vor über 10 Jahren eben verabsäumt hat, eine Nachfolgeregelung oder eine Verlängerungsregelung zu vereinbaren und wir deshalb jetzt aus Sicht der anderen zumindest in einer rechtlich nicht günstigen Position sind. Wir kämpfen trotzdem bis zur letzten Sekunde, Frau Abgeordnete, das können Sie mir glauben! Dazu brauche ich auch keine Aktuelle Stunde im Parlament, das tue ich auf jeden Fall. Ich habe in Tirol – und dazu stehe ich! – gesagt, dass ich für eine Nachfolgeregelung kämpfen werde, nicht nur, wie es sich für einen österreichischen Verkehrsminister gehört, nicht nur, wie es sich für einen Bürger gehört, dem die Umwelt, dem die Gesundheit der Mitmenschen etwas wert ist, sondern ich werde so kämpfen, als wäre ich ein betroffener Tiroler. Glauben Sie mir das! Glauben Sie mir weiters, dass auch im Hinblick auf den Transit, der in Tirol ein Ausmaß angenommen hat, das wirklich nicht zumutbar ist, wir uns auch Gedanken darüber machen, wie wir innerstaatlich Verbesserungen vornehmen können. Glauben Sie mir, es war kein Zufall, dass ich am 20. August, nachdem ich die Sommerzeit genutzt und mir darüber Gedanken gemacht habe, in Tirol ein Modell vorgestellt habe, das nicht die endgültige Lösung, aber zumindest ein Tropfen auf dem heißen Stein ist. Ich halte es nämlich für gescheit, Verkehrsbeeinflussungsanlagen erstens überhaupt möglichst bald zu installieren, da wir dadurch jenen Verkehr, der unvermeidbar ist, besser managen können, und zweitens diese Verkehrsbeeinflussungsanlagen, die mit einem Investitionsvolumen von 200 Millionen € bis 2008 österreichweit installiert sein werden, zunächst an die Immissionsmessstellen insbesondere in den sensiblen Gebieten zu koppeln. Ich habe deshalb versprochen, dass der Realisierungsauftrag in der Größenordung von 30 Millionen € noch im September von mir vergeben wird, dass die Verkehrsbeeinflussungsanlage im Großraum Innsbruck als Erste realisiert und bis Ende nächsten Jahres fertig sein wird, sodass dann Möglichkeiten bestehen, sobald der Schadstoffausstoß, die Luftverschmutzung, die gesamte Problematik einen gewissen Grenzwert erreicht, zu reagieren, indem ich Fahrverbote für bestimmte LKW-Klassen, zum Beispiel Euro 0, Euro 1 und Euro 2, ausspreche, indem ich Maßnahmen setze wie etwa eine Geschwindigkeitsreduktion, wenn dadurch gewährleistet ist, dass sich die Luftverschmutzung reduziert und Ähnliches mehr. – Ich halte das für eine Idee, die zumindest verfolgenswert ist. Wir werden sehen, was sie bringt. Ich halte es aber auch für notwendig, geschätzte Kollegin, dass wir auch weiterhin dafür kämpfen und Anreize schaffen, dass die Gütertransporte der LKW auf die Schiene verlagert werden. Dazu muss ich schon erwähnen, dass – Sie nehmen das meist einfach nur zur Kenntnis – es nicht so einfach war, am 10. September gemeinsam mit Kollegen Lunardi ein Memorandum zu unterschreiben, das nun die Phase 2 des Baus des Brenner-Basistunnels festlegt, also was die Finanzierung betrifft, was die technische Machbarkeit betrifft, was die Vorbereitung des Staatsvertrages betrifft, was die Abwicklung im Detail, das Zeitmanagement, betrifft, sodass der Brenner-Basistunnel bis 2006 baureif sein soll. Es ist alles genau, detailliert festgelegt, und damit wurden auch bereits 90 Millionen € freigegeben – 50 Prozent bezahlt die EU, den Rest teilen sich Italien und Österreich. Mit diesen 90 Millionen € wird detaillierter geplant, werden Probebohrungen vorgenommen, werden Verhandlungen geführt, werden Finanzierungsmodelle erstellt und Ähnliches mehr. Wir gehen also einen großen Schritt weiter in Richtung Verlagerung auf die Schiene. Nehmen Sie das, bitte, auch einmal positiv zur Kenntnis! Seien Sie einmal gut gewillt und erkennen Sie, dass diese österreichische Bundesregierung, dass dieser österreichische Verkehrsminister die Problematik, die Sensibilität, auch den Zeitdruck erkannt hat und alles dafür tut – in Österreich, in Tirol, in Italien, in Brüssel –, um die Situation, insbesondere jene der Anrainer, und zwar nicht nur in Tirol, sondern auch am Pyhrnpass, auch am Tauernpass, zu verbessern und die Lebensqualität wieder halbwegs so zu gestalten, dass sie verträglich, dass sie gut, dass sie auch geeignet ist, sich darüber zu freuen, wenn man dort wohnt. Noch etwas, das mir nicht unwichtig erscheint, weil ich versprochen habe, das bei jeder Gelegenheit zu sagen: Wissen Sie, was mich betroffen macht? – Mich machen auch jene Auswirkungen des österreichischen LKW-Verkehrs, und zwar nicht nur des Transitverkehrs, sondern insgesamt, betroffen, die im Bericht der WHO nachzulesen sind – sie werden ihn kennen, er ist unbestritten und unwidersprochen –, wonach aufgrund des Schadstoffausstoßes der österreichischen LKW pro Jahr 2400 vorzeitige Todesfälle zu verzeichnen sind, 2700 zusätzliche Fälle von chronischer Bronchitis bei Erwachsenen, 20 600 zusätzliche Fälle von chronischer Bronchitis bei Kindern unter 15 Jahren und 1,3 Millionen zusätzliche Krankenstandstage zu verzeichnen sind. Das kann man nicht oft genug erwähnen! Wissen Sie, wem ich das zuletzt, nämlich gestern, erzählt habe? – Herrn Riccardo Illy, dem Präsidenten der Region Friaul-Julisch Venetien, der mich besucht hat und ebenfalls mit mir über mehr Ökopunkte reden wollte und darüber, warum wir das denn nicht endlich alles vergessen, wir sollten doch den freien Warenverkehr forcieren. Ich habe ihm diese Zahlen gesagt, und damit war das Gespräch auf einer anderen Ebene, weil ihn das eben auch betroffen macht. Also: Wir tun ohnehin alles, was man tun kann. Helfen Sie uns! Packen wir das gemeinsam an! Frau Kollegin, es wäre sehr dienlich gewesen, wenn auch Ihre Fraktion im EU-Parlament dem Caveri-Bericht nicht zugestimmt, sondern die österreichischen Interessen vertreten hätte. Das war aber nicht der Fall. Vielleicht gelingt es jetzt, im Vermittlungsverfahren die österreichischen Interessen dort gemeinsam zu vertreten. Ich bin für ein gemeinsames Vorgehen immer zu haben, habe bereits wieder Termine mit den wichtigen Entscheidungsträgern in diesem Vermittlungsverfahren, mit den österreichischen Delegierten im EU-Parlament, denn mir ist die Sensibilität der Transitproblematik sehr wohl bekannt. Mir kann man jedenfalls nicht vorwerfen, dass ich das bagatellisiere. Es ist aber auch klar: Ich werde die Situation rund um die LKW und den Transit auf der Straße niemals ausnützen, um die Leute gegen die Wirtschaft aufzuhetzen, um mit durchaus berechtigten Anliegen Arbeitsplätze zu gefährden. Wir brauchen alles! Es gehört zur Lebensqualität auch ein Arbeitsplatz, auch ein Transport von A nach B – und eben eine gesunde Umwelt. Wir werden das Beste tun, damit wir das bestmöglich unter einen Hut bringen. 9.28 \n",
      "Predicted party: 0\n"
     ]
    }
   ],
   "source": [
    "# Test party classification.\"\n",
    "test_text= train_texts[0]\n",
    "test_text1= train_texts[1]\n",
    "test_text2= train_texts[2]\n",
    "test_text3= train_texts[3]\n",
    "party = predict_party(test_text, model, tokenizer, device)\n",
    "party1 = predict_party(test_text1, model, tokenizer, device)\n",
    "party2 = predict_party(test_text2, model, tokenizer, device)\n",
    "party3 = predict_party(test_text3, model, tokenizer, device)\n",
    "print(train_labels[0])\n",
    "print(test_text)\n",
    "print(f\"Predicted party: {party}\")\n",
    "print(train_labels[1])\n",
    "print(test_text1)\n",
    "print(f\"Predicted party: {party1}\")\n",
    "print(train_labels[2])\n",
    "print(test_text2)\n",
    "print(f\"Predicted party: {party2}\")\n",
    "print(train_labels[3])\n",
    "print(test_text3)\n",
    "print(f\"Predicted party: {party3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a753ea73",
   "metadata": {},
   "source": [
    "#### apply the train data on the model -> if it predicts good/ otherwise something is wrong with the training\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
